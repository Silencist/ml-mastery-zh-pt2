# 使用工作实例开发贝叶斯定理的直觉

> 原文：<https://machinelearningmastery.com/intuition-for-bayes-theorem-with-worked-examples/>

最后更新于 2020 年 8 月 19 日

贝叶斯定理为计算条件概率提供了一种有原则的方法。

这是一个看似简单的计算，为我们的直觉经常失灵的场景提供了一种易于使用的方法。

发展[贝叶斯定理](https://machinelearningmastery.com/bayes-theorem-for-machine-learning/)直觉的最佳方式是思考等式中术语的含义，并在一系列不同的现实场景中多次应用计算。这将提供正在计算的内容的上下文，以及将来在新场景中应用计算时可以作为起点的示例。

在本教程中，您将通过处理多个现实场景来发现计算贝叶斯定理的直觉。

完成本教程后，您将知道:

*   贝叶斯定理是一种计算条件概率的技术。
*   贝叶斯定理等式中术语的常用和有用的名称。
*   如何使用贝叶斯定理通过三个现实场景找到解决方案。

**用我的新书[机器学习概率](https://machinelearningmastery.com/probability-for-machine-learning/)启动你的项目**，包括*分步教程*和所有示例的 *Python 源代码*文件。

我们开始吧。

![How to Develop an Intuition for Bayes Theorem With Worked Examples](img/56419c2289be9152ed02d3d7b6b34c87.png)

如何通过工作实例发展贝叶斯定理的直觉
Phoo[土地管理局](https://flickr.com/photos/blmutah/33293078111/)，保留部分权利。

## 教程概述

本教程分为五个部分；它们是:

1.  贝叶斯定理介绍
2.  命名定理中的术语
3.  例 1:老年人跌倒和死亡
4.  示例 2:电子邮件和垃圾邮件检测
5.  示例 3:说谎者和测谎仪

## 贝叶斯定理介绍

条件概率是在给定另一事件发生的情况下，一个事件发生的概率，通常用两个因变量如 *X* 和 *Y* 的事件 *A* 和 *B* 来描述。

*   **条件概率**:一个(或多个)事件给定另一个事件发生的概率，例如 P(A 给定 B)或 P(A | B)。

条件概率可以使用联合概率来计算；例如:

*   P(A | B) = P(A 和 B) / P(B)

条件概率不对称；例如:

*   P(A | B)！= P(B | A)

然而，一个条件概率可以使用另一个条件概率来计算。

这叫做[贝叶斯定理](https://machinelearningmastery.com/bayes-theorem-for-machine-learning)，以[托马斯·贝叶斯牧师](https://en.wikipedia.org/wiki/Thomas_Bayes)命名，可以表述如下:

*   P(A|B) = P(B|A) * P(A) / P(B)

贝叶斯定理为计算条件概率提供了一种有原则的方法，也是使用联合概率的一种替代方法。

当联合概率难以计算时，或者当反向条件概率可用或易于计算时，这种计算条件概率的替代方法是有用的。

*   **贝叶斯定理**:在没有联合概率的情况下，计算条件概率的原则性方法。

通常情况下，我们无法直接获得分母，例如 P(B)。

我们可以用另一种方法来计算它；例如:

*   P(B)= P(B | A) * P(A)+P(B |不是 A)* P(不是 A)

这给出了贝叶斯定理的一个公式，我们可以使用它来替代 P(B)的计算，如下所述:

*   P(A | B)= P(B | A) * P(A)/P(B | A)* P(A)+P(B |不是 A)* P(不是 A)

**注**:分母就是我们上面给出的展开式。

因此，如果我们有 P(A)，那么我们可以计算 P(不是 A)作为它的补数；例如:

*   P(非 A)= 1–P(A)

另外，如果我们有 P(不是 B |不是 A)，那么我们可以计算 P(B |不是 A)作为它的补数；例如:

*   P(B |不是 A)= 1–P(不是 B |不是 A)

现在我们已经熟悉了贝叶斯定理的计算，让我们更仔细地看看等式中的术语的含义。

## 命名定理中的术语

贝叶斯定理等式中的术语根据使用该等式的上下文来命名。

从这些不同的角度思考计算是有帮助的，有助于将你的问题映射到等式上。

首先，一般情况下，结果 P(A|B)称为**后验概率**，P(A)称为**先验概率**。

*   P(A|B):后验概率。
*   P(A):先验概率。

有时 P(B|A)被称为**可能性**，P(B)被称为**证据**。

*   P(B|A):可能性。
*   P(B):证据。

这使得贝叶斯定理可以重申为:

*   后验=可能性*先验/证据

我们可以用一个烟与火的案例来说明这一点。

假设有烟，发生火灾的概率是多少？

其中 P(火)是先验，P(烟|火)是可能性，P(烟)是证据:

*   P(火|烟)= P(烟|火)* P(火)/ P(烟)

你可以想象雨和云的情况。

我们也可以用二进制分类器来考虑计算。

例如，P(B|A)可称为真阳性率(TPR)或**灵敏度**，P(B |非 A)可称为假阳性率(FPR)，补体 P(非 B |非 A)可称为真阴性率(TNR)或**特异性**，我们正在计算的 P(A|B)值可称为阳性预测值(PPV)或**准确率**。

*   p(非 B |非 A):真阴性率或 TNR ( **特异性**)。
*   p(B |不是 A):假阳性率或 FPR。
*   p(不是 B|A):假阴性率或 FNR。
*   P(B|A):真阳性率或 TPR ( **灵敏度**或回忆)。
*   P(A|B):阳性预测值或 PPV ( **准确率**)。

例如，我们可以使用以下术语重新表述计算:

*   PPV = (TPR * P(A)) / (TPR * P(A) + FPR * P(非 A))

这是一个关于贝叶斯定理的有用观点，将在教程中进一步阐述:

*   [机器学习贝叶斯定理的温和介绍](https://machinelearningmastery.com/bayes-theorem-for-machine-learning)

现在我们已经熟悉了贝叶斯定理和术语的含义，让我们看看一些我们可以计算它的场景。

请注意，以下所有示例都是人为设计的；它们不是基于真实世界的概率。

## 例 1:老年人跌倒和死亡

考虑老年人(80 岁以上)跌倒的情况；他们死于坠落的概率有多大？

让我们假设某个老年人死亡 P(A)的基础率是 10%，老年人跌倒 P(B)的基础率是 5%，从所有老年人来看，7%的死者有跌倒 P(B|A)。

让我们把我们知道的插入定理:

*   P(A|B) = P(B|A) * P(A) / P(B)
*   P(模|落)= P(落|模)* P(模)/ P(落)

或者

*   p(模|落)= 0.07 * 0.10 / 0.05
*   p(模|落)= 0.14

也就是说，如果一个老年人跌倒，那么他们死于跌倒的概率为 14%。

为了使这变得具体，我们可以用 Python 执行计算，首先定义我们知道的内容，然后使用贝叶斯定理来计算结果。

下面列出了完整的示例。

```py
# calculate P(A|B) given P(B|A), P(A) and P(B)
def bayes_theorem(p_a, p_b, p_b_given_a):
	# calculate P(A|B) = P(B|A) * P(A) / P(B)
	p_a_given_b = (p_b_given_a * p_a) / p_b
	return p_a_given_b

# P(A)
p_a = 0.10
# P(B)
p_b = 0.05
# P(B|A)
p_b_given_a = 0.07
# calculate P(A|B)
result = bayes_theorem(p_a, p_b, p_b_given_a)
# summarize
print('P(A|B) = %.3f%%' % (result * 100))
```

运行该示例确认了我们手动计算的值。

```py
P(A|B) = 14%
```

## 示例 2:电子邮件和垃圾邮件检测

考虑这样的情况:我们收到一封电子邮件，垃圾邮件检测器将其放在垃圾邮件文件夹中；它是垃圾邮件的概率有多大？

让我们假设一些细节，比如我们收到的电子邮件中有 2%是垃圾邮件。让我们假设垃圾邮件检测器真的很好，当一封电子邮件是垃圾邮件时，它以 99%的准确率检测到它 P(B|A)，当一封电子邮件不是垃圾邮件时，它将以 0.1% P(B |不是 A)的极低比率将其标记为垃圾邮件。

让我们把我们知道的插入定理:

*   P(A|B) = P(B|A) * P(A) / P(B)
*   P(垃圾邮件|检测到)= P(检测到|垃圾邮件)* P(垃圾邮件)/ P(检测到)

或者

*   P(垃圾邮件|检测到)= 0.99 * 0.02 / P(检测到)

我们不知道 P(B)，也就是 P(已检测到)，但我们可以使用以下公式计算:

*   P(B)= P(B | A) * P(A)+P(B |不是 A)* P(不是 A)

或者就我们的问题而言:

*   P(检测到)= P(检测到|垃圾邮件)* P(垃圾邮件)+ P(检测到|不是垃圾邮件)* P(不是垃圾邮件)

我们知道 P(检测到|不是垃圾邮件)，这是 0.1%，我们可以将 P(不是垃圾邮件)计算为 1–P(垃圾邮件)；例如:

*   P(非垃圾邮件)= 1–P(垃圾邮件)
*   p(非垃圾邮件)= 1–0.02
*   p(非垃圾邮件)= 0.98

因此，我们可以将 P(检测到的)计算为:

*   p(检出)= 0.99 * 0.02 + 0.001 * 0.98
*   p(检测到)= 0.0198 + 0.00098
*   p(检测到)= 0.02078

也就是说，大约 2%的电子邮件被检测为垃圾邮件，无论它们是否是垃圾邮件。

现在我们可以将答案计算为:

*   p(垃圾邮件|检测到)= 0.99 * 0.02 / 0.02078
*   p(垃圾邮件|检测到)= 0.0198 / 0.02078
*   p(垃圾邮件|检测到)= 0.95283926852743

也就是说，如果一封电子邮件在垃圾邮件文件夹中，那么它实际上是垃圾邮件的概率为 95.2%。

同样，让我们用 Python 中的一个例子来计算这个结果，以此来确认这个结果。

下面列出了完整的示例。

```py
# calculate the probability of an email in the spam folder being spam

# calculate P(A|B) given P(A), P(B|A), P(B|not A)
def bayes_theorem(p_a, p_b_given_a, p_b_given_not_a):
	# calculate P(not A)
	not_a = 1 - p_a
	# calculate P(B)
	p_b = p_b_given_a * p_a + p_b_given_not_a * not_a
	# calculate P(A|B)
	p_a_given_b = (p_b_given_a * p_a) / p_b
	return p_a_given_b

# P(A)
p_a = 0.02
# P(B|A)
p_b_given_a = 0.99
# P(B|not A)
p_b_given_not_a = 0.001
# calculate P(A|B)
result = bayes_theorem(p_a, p_b_given_a, p_b_given_not_a)
# summarize
print('P(A|B) = %.3f%%' % (result * 100))
```

运行该示例给出了相同的结果，证实了我们的手动计算。

```py
P(A|B) = 95.284%
```

## 示例 3:说谎者和测谎仪

考虑一个人用测谎仪测试，测试显示他们在说谎的情况。这个人真的在说谎的概率有多大？

让我们假设一些细节，比如大多数被测试的人说的都是实话，比如 98%，这意味着(1–0.98)或 2%的人是骗子 P(A)。我们还假设当有人在说谎时，测试可以很好地检测到他们，但不是很好，比如 72%的时间 P(B|A)。我们还假设当机器说他们没有说谎时，97%的时间 P(不是 B |不是 A)都是这样。

让我们把我们知道的插入定理:

*   P(A|B) = P(B|A) * P(A) / P(B)
*   P(说谎|积极)= P(积极|说谎)* P(说谎)/ P(积极)

或者:

*   P(说谎|阳性)= 0.72 * 0.02 / P(阳性)

同样，我们不知道 P(B)，或者在这种情况下，通常检测器返回肯定结果的频率。

我们可以用下面的公式来计算:

*   P(B)= P(B | A) * P(A)+P(B |不是 A)* P(不是 A)

或者:

*   P(正)= P(正|说谎)* P(说谎)+ P(正|不说谎)* P(不说谎)

或者，用数字:

*   P(正)= 0.72 * 0.02 + P(正|不说谎)*(1–0.02)
*   P(正)= 0.72 * 0.02 + P(正|不说谎)* 0.98

在这种情况下，考虑到这个人没有说谎，我们不知道阳性检测结果的概率；那就是我们不知道假阳性率或假警报率。

这可以计算如下:

*   P(B |不是 A)= 1–P(不是 B |不是 A)

或者:

*   P(正|不说谎)= 1–P(不正|不说谎)
*   p(正|不说谎)= 1–0.97
*   p(正|不说谎)= 0.03

因此，我们可以将 P(B)或 P(正)计算为:

*   p(正)= 0.72 * 0.02 + 0.03 * 0.98
*   p(正)= 0.0144 + 0.0294
*   p(正)= 0.0438

也就是说，测试在大约 4%的时间内返回阳性结果，而不管这个人是否在撒谎。

我们现在可以为这个场景计算贝叶斯定理:

*   p(说谎|阳性)= 0.72 * 0.02 / 0.0438
*   p(说谎|阳性)= 0.0144 / 0.0438
*   p(说谎|阳性)= 0.328767123287671

也就是说，如果测谎仪测试的结果是肯定的，那么他们有 32.8%的概率是在撒谎。这是一个糟糕的测试！

最后，让我们用 Python 来确认这个计算。

下面列出了完整的示例。

```py
# calculate the probability of a person lying given a positive lie detector result

# calculate P(A|B) given P(A), P(B|A), P(not B|not A)
def bayes_theorem(p_a, p_b_given_a, p_not_b_given_not_a):
	# calculate P(not A)
	not_a = 1 - p_a
	# calculate P(B|not A)
	p_b_given_not_a = 1 - p_not_b_given_not_a
	# calculate P(B)
	p_b = p_b_given_a * p_a + p_b_given_not_a * not_a
	# calculate P(A|B)
	p_a_given_b = (p_b_given_a * p_a) / p_b
	return p_a_given_b

# P(A), base rate
p_a = 0.02
# P(B|A)
p_b_given_a = 0.72
# P(not B| not A)
p_not_b_given_not_a = 0.97
# calculate P(A|B)
result = bayes_theorem(p_a, p_b_given_a, p_not_b_given_not_a)
# summarize
print('P(A|B) = %.3f%%' % (result * 100))
```

运行该示例给出了相同的结果，证实了我们的手动计算。

```py
P(A|B) = 32.877%
```

## 进一步阅读

如果您想更深入地了解这个主题，本节将提供更多资源。

*   [机器学习贝叶斯定理的温和介绍](https://machinelearningmastery.com/bayes-theorem-for-machine-learning)
*   [贝叶斯定理，维基百科](https://en.wikipedia.org/wiki/Bayes%27_theorem)。

## 摘要

在本教程中，您通过处理多个现实场景，发现了计算贝叶斯定理的直觉。

具体来说，您了解到:

*   贝叶斯定理是一种计算条件概率的技术。
*   贝叶斯定理等式中术语的常用和有用的名称。
*   如何使用贝叶斯定理通过三个现实场景找到解决方案。

你有什么问题吗？
在下面的评论中提问，我会尽力回答。