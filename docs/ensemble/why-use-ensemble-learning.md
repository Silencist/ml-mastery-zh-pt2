# 为什么使用集成学习？

> 原文：<https://machinelearningmastery.com/why-use-ensemble-learning/>

最后更新于 2021 年 4 月 27 日

#### 集成方法对机器学习有什么好处？

集成是组合来自两个或更多其他模型的预测的预测模型。

集成学习方法很受欢迎，当预测建模项目的最佳表现是最重要的结果时，集成学习方法是首选技术。

然而，它们并不总是最适合使用的技术，应用机器学习领域的初学者期望集成或特定的集成方法总是最好的使用方法。

集成在预测建模项目中提供了两个具体的好处，了解这些好处是什么以及如何衡量它们以确保使用集成是您项目的正确决策非常重要。

在本教程中，您将发现使用集成方法进行机器学习的好处。

阅读本教程后，您将知道:

*   使用集成的最小好处是减少预测模型的平均技能的差异。
*   使用集成的一个主要好处是提高了集成中任何贡献成员的平均预测表现。
*   集成提高表现的机制通常是减少贡献模型产生的预测误差的方差分量。

**用我的新书[Python 集成学习算法](https://machinelearningmastery.com/ensemble-learning-algorithms-with-python/)启动你的项目**，包括*分步教程*和所有示例的 *Python 源代码*文件。

我们开始吧。

![Why Use Ensemble Learning](img/4d70c6d9528a92438c541a1ef93fad51.png)

为什么使用集成学习
胡安·安东尼奥·西格尔摄，部分版权已被保留。

## 教程概述

本教程分为四个部分；它们是:

1.  集成学习
2.  使用集成来提高健壮性
3.  偏差、方差和集成
4.  使用集成来提高表现

## 集成学习

集成是一种机器学习模型，它结合了来自两个或多个模型的预测。

对集合有贡献的模型，称为集合成员，可以是相同类型或不同类型，并且可以在相同的训练数据上训练或不训练。

集成成员做出的预测可以使用统计数据(如模式或平均值)进行组合，或者通过更复杂的方法进行组合，这些方法可以了解在什么条件下信任每个成员的程度。

对集成方法的研究真正开始于 20 世纪 90 年代，那十年发表了关于最流行和最广泛使用的方法的论文，如核心装袋、提升和堆叠方法。

在 21 世纪后期，集成的采用有所增加，部分原因是它们在机器学习竞赛中取得了巨大的成功，例如网飞奖和后来的卡格尔竞赛。

> 在过去的几十年里，多分类器系统，也称为集成系统，在计算智能和机器学习领域受到越来越多的关注。

—第 1 页，[集成机器学习](https://amzn.to/2C7syo5)，2012。

集成方法大大增加了计算成本和复杂性。这一增长来自于培训和维护多个模型而不是单个模型所需的专业知识和时间。这就引出了一个问题:

*   **为什么要考虑用集成？**

在单个模型上使用集合有两个主要原因，它们是相关的；它们是:

1.  **表现:**与任何单个贡献模型相比，集成可以做出更好的预测并获得更好的表现。
2.  **稳健性**:集合减少了预测和模型表现的传播或分散。

集成用于在预测建模问题上获得比单一预测模型更好的预测表现。实现这一点的方式可以理解为模型通过增加偏差来减少预测误差的方差分量(即在[偏差-方差权衡](https://machinelearningmastery.com/calculate-the-bias-variance-trade-off/)的背景下)。

> 最初是为了减少自动化决策系统的差异，从而提高准确性而开发的…

—第 1 页，[集成机器学习](https://amzn.to/2C7syo5)，2012。

集成方法的另一个重要且较少讨论的好处是提高了模型平均表现的稳健性或可靠性。

这些都是机器学习项目的重要关注点，有时我们可能更喜欢模型的一个或两个属性。

让我们仔细看看这两个属性，以便更好地理解在项目中使用集成学习的好处。

## 使用集成来提高健壮性

在预测建模项目中，我们通常会评估多个模型或建模管道，并选择一个表现良好或最好的模型作为我们的[最终模型](https://machinelearningmastery.com/train-final-machine-learning-model/)。

然后，算法或管道适用于所有可用数据，并用于对新数据进行预测。

从我们的测试工具中，我们知道了模型的平均表现，通常使用重复的 [k 倍交叉验证](https://machinelearningmastery.com/k-fold-cross-validation/)作为黄金标准进行评估。问题是，平均表现可能不够。

模型的平均准确率或误差是预期表现的总结，而事实上，一些模型在不同的数据子集上表现更好，而一些模型表现更差。

标准偏差是观察值和平均值之间的平均差异，总结了数据的离差或扩散。对于模型的准确性或误差度量，它可以让您了解模型行为的传播。

查看最小和最大模型表现分数将让您了解您可能期望从模型中获得的最差和最佳表现，这对于您的应用程序来说可能是不可接受的。

最简单的集成是在训练数据集上多次拟合模型，并使用汇总统计(如回归的平均值或分类模式)组合预测。重要的是，由于随机学习算法、训练数据集组成的差异或模型本身的差异，每个模型需要略有不同。

这将减少模型预测的差异。平均表现可能大致相同，尽管最坏和最好情况下的表现会更接近平均表现。

实际上，它平滑了模型的预期表现。

我们可以称之为模型预期表现中的“*稳健性*”，这是使用集成方法的最小好处。

集合可能会也可能不会提高任何单个贡献成员的建模表现，这将在后面进一步讨论，但至少应该减少模型平均表现的差异。

有关此主题的更多信息，请参见教程:

*   [如何减少最终机器学习模型中的方差](https://machinelearningmastery.com/how-to-reduce-model-variance/)

## 偏差、方差和集成

用于分类和回归的机器学习模型学习从输入到输出的映射函数。

这种映射是从问题域(即训练数据集)的示例中获得的，并在训练期间未使用的数据(即测试数据集)上进行评估。

机器学习模型产生的错误通常用两个属性来描述:**偏差**和**方差**。

偏差是模型能够捕捉输入和输出之间映射函数的程度的度量。它抓住了模型的刚性:模型关于输入和输出之间映射的功能形式的假设的强度。

模型的方差是当模型适合不同的训练数据时，模型表现的变化量。它捕捉数据细节对模型的影响。

> 方差是指如果我们使用不同的训练数据集进行估计，那么[模型]将会改变的量。

—第 34 页，[R](https://amzn.to/2RC7ElX)中应用的统计学习介绍，2014。

模型表现的偏差和方差是有联系的。

理想情况下，我们更喜欢具有低偏差和低方差的模型，尽管在实践中，这非常具有挑战性。事实上，对于给定的预测建模问题，这可以描述为应用机器学习的目标。

通过增加方差，通常可以很容易地减少偏差。相反，通过增加偏差可以很容易地降低方差。

> 这被称为权衡，因为很容易获得偏差极低但方差高的方法……或偏差极低但方差高的方法……

—第 36 页，[R](https://amzn.to/2RC7ElX)中应用的统计学习介绍，2014。

一些模型自然具有高偏差或高方差，这通常可以通过使用改变算法学习行为的超参数来放宽或增加。

集成提供了一种减少预测方差的方法；这是可归因于“*方差*的预测误差量。”

情况并非总是如此，但如果是这样，方差的减少反过来又会提高预测表现。

> 经验和理论证据表明，一些集成技术(如 bagging)充当方差减少机制，即它们减少误差的方差分量。此外，经验结果表明，其他集成技术(如 AdaBoost)减少了误差的偏差和方差部分。

—第 39 页，[使用集成方法的模式分类](https://amzn.to/2zxc0F7)，2010。

使用集成来降低预测误差的方差特性首先会带来使用集成的主要好处:提高预测表现。

## 使用集成来提高表现

减少预测误差的方差元素提高了预测表现。

我们明确地使用集成学习来寻求更好的预测表现，例如更低的回归误差或更高的分类准确率。

> ……有一种比明智的算法选择更容易、更强大的提高模型准确率的方法:可以将模型集合成集合。

—第 2 页，[数据挖掘中的集成方法](https://amzn.to/3frGM1A)，2010。

这是集成学习方法的**主要用途，也是大多数机器学习竞赛(如网飞奖和卡格尔竞赛)获奖者使用集成所展示的益处。**

> 在 Netflix 奖中，一项为期两年的竞赛将赢得 100 万美元，在该竞赛中，第一个提交模型的团队将网飞的内部推荐系统改进 10%。[……]最终优势是通过权衡多达 30 家竞争对手的车型贡献获得的。

—第 8 页，[数据挖掘中的集成方法](https://amzn.to/3frGM1A)，2010。

学术竞赛也证明了这一优势，例如计算机视觉领域著名的 ImageNet 数据集的顶级解决方案。

> 这些剩余网的集合在 ImageNet 测试集上实现了 3.57%的误差。这一结果获得了 ILSVRC 2015 分类任务的第一名。

——[图像识别的深度残差学习](https://arxiv.org/abs/1512.03385)，2015。

当以这种方式使用时，只有当集成比集成中的任何成员平均表现更好时，才应该采用集成。如果不是这样，那么应该使用表现更好的贡献成员。

考虑由模型在测试工具上计算的预期分数的分布，例如重复的 k 倍交叉验证，正如我们在上面考虑由集合提供的“*稳健性*”时所做的那样。实际上，减少误差方差的集合将改变分布，而不是简单地缩小分布的范围。

与任何单一型号相比，这可以带来更好的平均表现。

并不总是这样，有这种期待是初学者常犯的错误。

集成团的表演不可能比集成团中表现最好的成员表现得更好，这是可能的，甚至是常见的。如果集成团有一个表现最好的模型，而其他成员没有提供任何好处，或者集成团不能有效地利用他们的贡献，这种情况就会发生。

一个集成团也有可能表现得比集成团中表现最好的成员差。这种情况也很常见，通常涉及一个表现最好的模型，其预测被一个或多个表现不佳的其他模型变得更糟，整个团队无法有效利用它们的贡献。

因此，测试一套集成方法并调整它们的行为是很重要的，就像我们对任何单独的机器学习模型所做的那样。

## 进一步阅读

如果您想更深入地了解这个主题，本节将提供更多资源。

### 相关教程

*   [如何减少最终机器学习模型中的方差](https://machinelearningmastery.com/how-to-reduce-model-variance/)
*   [如何开发水平投票深度学习集成来减少差异](https://machinelearningmastery.com/horizontal-voting-ensemble/)

### 书

*   [使用集成方法的模式分类](https://amzn.to/2zxc0F7)，2010。
*   [集成方法](https://amzn.to/2XZzrjG)，2012。
*   [集成机器学习](https://amzn.to/2C7syo5)，2012。
*   [数据挖掘中的集成方法](https://amzn.to/3frGM1A)，2010。

### 文章

*   一起学习，维基百科。
*   [一起学习，学院派](http://www.scholarpedia.org/article/Ensemble_learning)。

## 摘要

在这篇文章中，你发现了使用集成方法进行机器学习的好处。

具体来说，您了解到:

*   使用集成的最小好处是减少预测模型的平均技能的差异。
*   使用集成的一个主要好处是提高了集成中任何贡献成员的平均预测表现。
*   集成提高表现的机制通常是减少贡献模型产生的预测误差的方差分量。

**你有什么问题吗？**
在下面的评论中提问，我会尽力回答。