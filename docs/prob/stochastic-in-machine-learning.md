# 随机在机器学习中意味着什么？

> 原文：<https://machinelearningmastery.com/stochastic-in-machine-learning/>

最后更新于 2020 年 7 月 24 日

许多机器学习算法的行为和表现被称为随机的。

随机是指一个变量过程，其结果包含一些随机性，并具有一些不确定性。它是一个数学术语，与“*随机性*”和“*概率性*”密切相关，可以与“*确定性*的思想相对比。”

机器学习算法的随机性质是机器学习中的一个重要的基础概念，为了有效地解释许多预测模型的行为，需要理解它。

在这篇文章中，你会发现一个关于机器学习随机性的温和介绍。

看完这篇文章，你会知道:

*   如果结果中包含不确定性或随机性，那么变量或过程就是随机的。
*   随机是随机和概率的同义词，虽然与非确定性不同。
*   许多机器学习算法是随机的，因为它们在优化或学习过程中明确使用了随机性。

**用我的新书[机器学习概率](https://machinelearningmastery.com/probability-for-machine-learning/)启动你的项目**，包括*分步教程*和所有示例的 *Python 源代码*文件。

我们开始吧。

![A Gentle Introduction to Stochastic in Machine Learning](img/ac92b1318b6478f56438e29db68f8de4.png)

机器学习中随机的温和介绍
图片由[贾尔斯·特恩布尔](https://www.flickr.com/photos/gilest/36570667440/)提供，版权所有。

## 概观

本教程分为三个部分；它们是:

1.  *随机*是什么意思？
2.  随机与随机、概率和不确定
3.  机器学习中的随机性

## *随机*是什么意思？

如果事件或结果的发生涉及随机性或不确定性，则变量为[随机](https://en.wikipedia.org/wiki/Stochastic)。

> “随机”是指模型具有某种随机性

—第 66 页，[思考贝叶斯](https://amzn.to/2LgElT9)。

如果一个[过程控制一个或多个随机变量，那么它就是随机的](https://en.wikipedia.org/wiki/Stochastic_process)。

游戏是随机的，因为它们包含了随机性的元素，比如纸牌游戏和棋盘游戏中的洗牌或掷骰子。

> 在现实生活中，许多不可预测的外部事件会让我们陷入不可预见的境地。许多游戏通过包含随机元素来反映这种不可预测性，例如掷骰子。我们称之为随机博弈。

—第 177 页，[人工智能:现代方法](https://amzn.to/2Y7yCpO)，第 3 版，2009 年。

随机通常用于描述使用或利用随机性的数学过程。常见的例子包括[布朗运动](https://en.wikipedia.org/wiki/Brownian_motion)、[马尔可夫过程](https://en.wikipedia.org/wiki/Markov_process)、[蒙特卡罗采样](https://en.wikipedia.org/wiki/Monte_Carlo_method)等等。

现在我们有了一些定义，让我们试着通过比较随机和其他不确定性的概念来添加更多的上下文。

## 随机与随机、概率和非确定性

在本节中，我们将尝试通过将变量或过程与相关术语“*随机*”、“*概率*”和“*非确定性*”进行比较，来更好地理解变量或过程是随机的这一想法

### 随机与随机

在统计学和概率学中，一个变量被称为“[随机变量](https://en.wikipedia.org/wiki/Random_variable)，可以呈现一个或多个结果或事件。

这是一个可以测量的事物的通用名称。

一般来说，随机是随机的同义词。

例如，随机变量就是随机变量。随机过程就是随机过程。

通常，随机用于表示序列中观察值之间缺乏相关性。例如，公平骰子的滚动是随机的，公平硬币的翻转也是随机的。

严格来说，一个随机变量或随机序列仍然可以用概率分布来概括；它可能只是一个均匀的分布。

如果我们对关注变量的概率性质感兴趣，比如下一个事件对当前事件的部分依赖，我们可以选择将某件事描述为随机的而不是随机的。如果我们想把注意力集中在事件的独立性上，我们可以选择随机而不是随机。

### 随机与概率

一般来说，随机是概率的同义词。

例如，随机变量或过程是概率性的。可以用概率的工具来总结和分析。

最值得注意的是，事件或序列中的下一个事件的分布可以用概率分布来描述。

如果我们希望强调相关性，例如如果我们使用参数模型或已知的概率分布来总结变量或序列，我们可以选择将变量或过程描述为概率而不是随机的。

### 随机与非确定性

如果序列中的下一个事件可以根据当前事件准确确定，那么变量或过程就是确定性的。

例如，[确定性算法](https://en.wikipedia.org/wiki/Deterministic_algorithm)在给定相同输入的情况下，总是会给出相同的结果。相反，非确定性算法可能对同一输入给出不同的结果。

随机变量或过程是不确定的，因为结果存在不确定性。

然而，随机变量或过程也不是[非确定性的](https://en.wikipedia.org/wiki/Nondeterministic_algorithm)，因为非确定性只描述结果的可能性，而不是概率。

把某件事描述成随机的比把它描述成不确定的更有说服力，因为我们可以在分析中使用概率工具，比如预期结果和方差。

> ……“随机”通常意味着结果的不确定性是用概率来量化的；一个不确定的环境是这样一个环境，在这个环境中，行动以其可能的结果为特征，但没有概率与之相关联。

—第 43 页，[人工智能:现代方法](https://amzn.to/2Y7yCpO)，第 3 版，2009 年。

## 机器学习中的随机性

许多机器学习算法和模型被描述为随机的。

这是因为许多优化和学习算法都必须在随机域中运行，并且因为一些算法利用随机性或概率决策。

让我们仔细看看机器学习中不确定性的来源和随机算法的本质。

### 随机问题域

随机领域是那些涉及不确定性的领域。

> ……机器学习必须始终处理不确定的量，有时可能还需要处理随机(非确定性)量。不确定性和随机性可以从许多来源产生。

—第 54 页，[深度学习](https://amzn.to/2lnc3vL)，2016。

这种不确定性可能来自受统计噪声或随机误差影响的目标或目标函数。

这也可能是因为用于拟合模型的数据是来自更广泛人群的不完整样本。

最后，所选择的模型很少能够捕捉到该领域的所有方面，而是必须推广到看不见的情况，并失去一些保真度。

### 随机优化算法

随机优化是指一个优化算法领域，该领域明确使用随机性来寻找目标函数的最优值，或者优化本身具有随机性(统计噪声)的目标函数。

最常见的是，[随机优化算法](https://en.wikipedia.org/wiki/Stochastic_optimization)在探索搜索空间和利用已经了解的搜索空间之间寻求平衡，以便钻研最优解。搜索空间中下一个位置的选择是随机选择的，即基于最近搜索了哪些区域的概率。

> 随机爬山从上坡动作中随机选择；选择的概率可以随着上坡运动的陡度而变化。

—第 124 页，[人工智能:现代方法](https://amzn.to/2Y7yCpO)，第 3 版，2009 年。

随机优化算法的常见例子有:

*   模拟退火
*   遗传算法
*   粒子群优化算法

> 粒子群优化算法是一种随机优化方法，模拟鸟群的社会行为。

—第 9 页，[计算智能:简介](https://amzn.to/2zMxdqX)。

### 随机学习算法

大多数机器学习算法是随机的，因为它们在学习过程中利用了随机性。

使用随机性是一种特性，而不是 bug。它允许算法避免陷入困境，并实现确定性(非随机)算法无法实现的结果。

例如，一些机器学习算法甚至在其名称中包含“*随机*”，例如:

*   随机梯度下降(优化算法)。
*   随机梯度提升(集成算法)。

[随机梯度下降](https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/)优化模型的参数，例如人工神经网络，这包括在每次迭代之前随机洗牌训练数据集，这导致模型参数的不同顺序的更新。此外，神经网络中的模型权重通常被初始化为随机起点。

> 大多数深度学习算法都是基于一种叫做随机梯度下降的优化算法。

—第 98 页，[深度学习](https://amzn.to/2lnc3vL)，2016。

[随机梯度提升](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)是决策树算法的集合。随机方面指的是从用于构建树的训练数据集中选择的随机行子集，特别是树的分裂点。

### 随机算法行为

因为许多机器学习算法利用随机性，所以它们的本质(例如行为和表现)也是随机的。

机器学习算法的随机性质最常见于用于分类和回归预测建模问题的复杂和非线性方法。

这些算法在从训练数据构建模型的过程中利用随机性，这具有每次在相同数据上运行相同算法时拟合不同模型的效果。反过来，在等待测试数据集上评估时，略有不同的模型具有不同的表现。

非线性机器学习算法的这种随机行为对于初学者来说是具有挑战性的，他们假设学习算法将是确定性的，例如，当算法在相同的数据上运行时，适合相同的模型。

这种随机行为要求必须使用描述模型的平均或预期表现的汇总统计数据来总结模型的表现，而不是任何单次训练运行的模型表现。

关于这个主题的更多信息，请查看帖子:

*   [拥抱机器学习中的随机性](https://machinelearningmastery.com/randomness-in-machine-learning/)

## 进一步阅读

如果您想更深入地了解这个主题，本节将提供更多资源。

### 邮件

*   [如何在 Python 中生成随机数](https://machinelearningmastery.com/how-to-generate-random-numbers-in-python/)
*   [Python 机器学习随机数生成器介绍](https://machinelearningmastery.com/introduction-to-random-number-generators-for-machine-learning/)
*   [拥抱机器学习中的随机性](https://machinelearningmastery.com/randomness-in-machine-learning/)
*   [为什么用随机权重初始化神经网络？](https://machinelearningmastery.com/why-initialize-a-neural-network-with-random-weights/)
*   [使用 XGBoost 和 scikit-学习 Python 的随机梯度提升](https://machinelearningmastery.com/stochastic-gradient-boosting-xgboost-Sklearn-python/)

### 文章

*   [随机变量，维基百科](https://en.wikipedia.org/wiki/Random_variable)。
*   [统计随机性，维基百科](https://en.wikipedia.org/wiki/Statistical_randomness)。
*   [随机，维基百科](https://en.wikipedia.org/wiki/Stochastic)。
*   [随机过程，维基百科](https://en.wikipedia.org/wiki/Stochastic_process)。
*   [随机优化](https://en.wikipedia.org/wiki/Stochastic_optimization)。

## 摘要

在这篇文章中，你发现了机器学习随机性的温和介绍。

具体来说，您了解到:

*   如果结果中包含不确定性或随机性，那么变量或过程就是随机的。
*   随机是随机和概率的同义词，虽然与非确定性不同。
*   许多机器学习算法是随机的，因为它们在优化或学习过程中明确使用了随机性。

你有什么问题吗？
在下面的评论中提问，我会尽力回答。