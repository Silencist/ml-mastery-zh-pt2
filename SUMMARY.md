+   [Machine Learning Mastery 计算机视觉教程](docs/cv/README.md)
    +   [通道在前和通道在后图像格式的温和介绍](docs/cv/a-gentle-introduction-to-channels-first-and-channels-last-image-formats-for-deep-learning.md)
    +   [深度学习在计算机视觉中的 9 个应用](docs/cv/applications-of-deep-learning-for-computer-vision.md)
    +   [为 CNN 准备和扩充图像数据的最佳实践](docs/cv/best-practices-for-preparing-and-augmenting-image-data-for-convolutional-neural-networks.md)
    +   [8 本计算机视觉入门书籍](docs/cv/computer-vision-books.md)
    +   [卷积层在深度学习神经网络中是如何工作的？](docs/cv/convolutional-layers-for-deep-learning-neural-networks.md)
    +   [DeepLearningAI 卷积神经网络课程（复习）](docs/cv/deeplearning-ai-convolutional-neural-networks-deep-learning-specialization-review.md)
    +   [如何在 Keras 中配置图像数据扩充](docs/cv/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks.md)
    +   [如何从零开始为 CIFAR-10 照片分类开发 CNN](docs/cv/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification.md)
    +   [用于 Fashion-MNIST 服装分类的深度学习 CNN](docs/cv/how-to-develop-a-cnn-from-scratch-for-fashion-mnist-clothing-classification.md)
    +   [如何为 MNIST 手写数字分类开发 CNN](docs/cv/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification.md)
    +   [如何分类猫狗照片（准确率 97%）](docs/cv/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats.md)
    +   [亚马逊雨林卫星照片多标签分类](docs/cv/how-to-develop-a-convolutional-neural-network-to-classify-satellite-photos-of-the-amazon-rainforest.md)
    +   [如何使用 FaceNet 在 Keras 中开发人脸识别系统](docs/cv/how-to-develop-a-face-recognition-system-using-facenet-in-keras-and-an-svm-classifier.md)
    +   [如何通过深度学习开发计算机视觉能力](docs/cv/how-to-develop-and-demonstrate-competence-with-deep-learning-for-computer-vision.md)
    +   [如何用 CNN 评估图像分类的像素缩放方法](docs/cv/how-to-evaluate-pixel-scaling-methods-for-image-classification.md)
    +   [如何开始计算机视觉深度学习（7 天迷你课程）](docs/cv/how-to-get-started-with-deep-learning-for-computer-vision-7-day-mini-course.md)
    +   [如何在 Keras 从头开发 VGG、Inception 和 ResNet 模块](docs/cv/how-to-implement-major-architecture-innovations-for-convolutional-neural-networks.md)
    +   [如何使用 PIL/Pillow](docs/cv/how-to-load-and-manipulate-images-for-deep-learning-in-python-with-pil-pillow.md)
    +   [如何用 Keras 加载和可视化标准计算机视觉数据集](docs/cv/how-to-load-and-visualize-standard-computer-vision-datasets-with-keras.md)
    +   [如何使用 Keras API 加载、转换和保存图像](docs/cv/how-to-load-convert-and-save-images-with-the-keras-api.md)
    +   [如何为 Keras 深度学习从目录加载大数据集](docs/cv/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras.md)
    +   [如何为深度学习手动缩放图像像素数据](docs/cv/how-to-manually-scale-image-pixel-data-for-deep-learning.md)
    +   [如何在 Keras 中对图像像素归一化、居中和标准化](docs/cv/how-to-normalize-center-and-standardize-images-with-the-imagedatagenerator-in-keras.md)
    +   [如何将深度学习用于人脸检测](docs/cv/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras.md)
    +   [如何在 Keras 中将 VGGFace2 用于人脸识别](docs/cv/how-to-perform-face-recognition-with-vggface2-convolutional-neural-network-in-keras.md)
    +   [如何在 Keras 中将 Mask RCNN 用于照片中的对象检测](docs/cv/how-to-perform-object-detection-in-photographs-with-mask-r-cnn-in-keras.md)
    +   [如何在 Keras 中将 YOLOv3 用于对象检测](docs/cv/how-to-perform-object-detection-with-yolov3-in-keras.md)
    +   [如何使用 Keras 训练对象检测模型](docs/cv/how-to-train-an-object-detection-model-with-keras.md)
    +   [如何使用测试时间扩充做出更好的预测](docs/cv/how-to-use-test-time-augmentation-to-improve-model-performance-for-image-classification.md)
    +   [在 Keras 中将计算机视觉模型用于迁移学习](docs/cv/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models.md)
    +   [如何在卷积神经网络中可视化过滤器和特征图](docs/cv/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks.md)
    +   [用于管理模型复杂性`1×1`卷积的温和介绍](docs/cv/introduction-to-1x1-convolutions-to-reduce-the-complexity-of-convolutional-neural-networks.md)
    +   [面向人脸识别的深度学习入门](docs/cv/introduction-to-deep-learning-for-face-recognition.md)
    +   [ImageNet 挑战赛（ILSVRC）的温和介绍](docs/cv/introduction-to-the-imagenet-large-scale-visual-recognition-challenge-ilsvrc.md)
    +   [深度学习对象识别入门](docs/cv/object-recognition-with-deep-learning.md)
    +   [用于人脸识别的单样本学习](docs/cv/one-shot-learning-with-siamese-networks-contrastive-and-triplet-loss-for-face-recognition.md)
    +   [卷积神经网络填充和步长的温和介绍](docs/cv/padding-and-stride-for-convolutional-neural-networks.md)
    +   [卷积神经网络池化层的简单介绍](docs/cv/pooling-layers-for-convolutional-neural-networks.md)
    +   [深度学习计算机视觉前景的温和介绍](docs/cv/promise-of-deep-learning-for-computer-vision.md)
    +   [用于图像分类的卷积神经网络模型创新](docs/cv/review-of-architectural-innovations-for-convolutional-neural-networks-for-image-classification.md)
    +   [斯坦福卷积神经网络视觉识别课程（复习）](docs/cv/stanford-convolutional-neural-networks-for-visual-recognition-course-review.md)
    +   [深度学习迁移学习入门](docs/cv/transfer-learning-for-deep-learning.md)
    +   [计算机视觉入门](docs/cv/what-is-computer-vision.md)
+   [Machine Learning Mastery 数据准备教程](docs/dataprep/README.md)
    +   [如何用 Python 进行机器学习的数据清洗](docs/dataprep/basic-data-cleaning-for-machine-learning.md)
    +   [为机器学习的缺失值添加二元标志](docs/dataprep/binary-flags-for-missing-values-for-machine-learning.md)
    +   [8 本关于数据清理和特征工程的顶级书籍](docs/dataprep/books-on-data-cleaning-data-preparation-and-feature-engineering.md)
    +   [如何用 Python 计算特征重要性](docs/dataprep/calculate-feature-importance-with-python.md)
    +   [如何选择机器学习的数据准备方式](docs/dataprep/choose-data-preparation-methods-for-machine-learning.md)
    +   [如何将列转换器用于数据准备](docs/dataprep/columntransformer-for-numerical-and-categorical-data.md)
    +   [如何为 Sklearn 创建自定义数据转换](docs/dataprep/create-custom-data-transforms-for-scikit-learn.md)
    +   [机器学习的数据准备（7 天迷你课程）](docs/dataprep/data-preparation-for-machine-learning-7-day-mini-course.md)
    +   [为什么数据准备在机器学习中如此重要](docs/dataprep/data-preparation-is-important.md)
    +   [机器学习的数据准备技术之旅](docs/dataprep/data-preparation-techniques-for-machine-learning.md)
    +   [执行数据准备时如何避免数据泄露](docs/dataprep/data-preparation-without-data-leakage.md)
    +   [6 种 Python 降维算法](docs/dataprep/dimensionality-reduction-algorithms-with-python.md)
    +   [机器学习降维介绍](docs/dataprep/dimensionality-reduction-for-machine-learning.md)
    +   [如何为机器学习使用离散化变换](docs/dataprep/discretization-transforms-for-machine-learning.md)
    +   [特征工程与选择（书评）](docs/dataprep/feature-engineering-and-selection-book-review.md)
    +   [如何为机器学习在表格数据上使用特征提取](docs/dataprep/feature-extraction-on-tabular-data.md)
    +   [如何对回归数据执行特征选择](docs/dataprep/feature-selection-for-regression-data.md)
    +   [如何对类别数据执行特征选择](docs/dataprep/feature-selection-with-categorical-data.md)
    +   [如何对数值输入数据执行特征选择](docs/dataprep/feature-selection-with-numerical-input-data.md)
    +   [如何选择机器学习的特征选择方法](docs/dataprep/feature-selection-with-real-and-categorical-data.md)
    +   [机器学习中数据准备技术的框架](docs/dataprep/framework-for-data-preparation-for-machine-learning.md)
    +   [如何网格搜索数据准备技术](docs/dataprep/grid-search-data-preparation-techniques.md)
    +   [如何爬坡机器学习测试集](docs/dataprep/hill-climb-the-test-set-for-machine-learning.md)
    +   [如何在 Sklearn 中保存和重用数据准备对象](docs/dataprep/how-to-save-and-load-models-and-data-preparation-in-scikit-learn-for-later-use.md)
    +   [如何在 Python 中转换回归的目标变量](docs/dataprep/how-to-transform-target-variables-for-regression-with-scikit-learn.md)
    +   [机器学习中缺失值的迭代插补](docs/dataprep/iterative-imputation-for-missing-values-in-machine-learning.md)
    +   [机器学习中缺失值的 KNN 插补](docs/dataprep/knn-imputation-for-missing-values-in-machine-learning.md)
    +   [Python 中用于降维的线性判别分析](docs/dataprep/linear-discriminant-analysis-for-dimensionality-reduction-in-python.md)
    +   [Python 中的 4 种自动异常值检测算法](docs/dataprep/model-based-outlier-detection-and-removal-in-python.md)
    +   [类别数据的顺序编码和单热编码](docs/dataprep/one-hot-encoding-for-categorical-data.md)
    +   [如何为机器学习使用多项式特征变换](docs/dataprep/polynomial-features-transforms-for-machine-learning.md)
    +   [如何为机器学习使用幂变换](docs/dataprep/power-transforms-with-scikit-learn.md)
    +   [Python 中用于降维的主成分分析](docs/dataprep/principal-components-analysis-for-dimensionality-reduction-in-python.md)
    +   [如何为机器学习使用分位数变换](docs/dataprep/quantile-transforms-for-machine-learning.md)
    +   [Python 中用于特征选择的递归特征消除（RFE）](docs/dataprep/rfe-feature-selection-in-python.md)
    +   [如何为机器学习缩放带有异常值的数据](docs/dataprep/robust-scaler-transforms-for-machine-learning.md)
    +   [如何选择性缩放机器学习的数值输入变量](docs/dataprep/selectively-scale-numerical-input-variables-for-machine-learning.md)
    +   [Python 中用于降维的奇异值分解](docs/dataprep/singular-value-decomposition-for-dimensionality-reduction-in-python.md)
    +   [如何在 Python 中使用标准缩放器和最小最大缩放器变换](docs/dataprep/standardscaler-and-minmaxscaler-transforms-in-python.md)
    +   [机器学习中缺失值的统计插补](docs/dataprep/statistical-imputation-for-missing-values-in-machine-learning.md)
    +   [使用 Sklearn 的表格数据测试时间增强](docs/dataprep/test-time-augmentation-with-scikit-learn.md)
    +   [如何在机器学习中训练测试集](docs/dataprep/train-to-the-test-set-in-machine-learning.md)
    +   [什么是机器学习项目中的数据准备](docs/dataprep/what-is-data-preparation-in-machine-learning.md)
+   [Machine Learning Mastery 深度学习表现教程](docs/dlperf/README.md)
    +   [训练深度学习神经网络模型的挑战的温和介绍](docs/dlperf/a-gentle-introduction-to-the-challenge-of-training-deep-learning-neural-network-models.md)
    +   [深度学习中激活正则化的温和介绍](docs/dlperf/activation-regularization-for-reducing-generalization-error-in-deep-learning-neural-networks.md)
    +   [深度学习 Adam 优化算法的温和介绍](docs/dlperf/adam-optimization-algorithm-for-deep-learning.md)
    +   [深度神经网络批量归一化简介](docs/dlperf/batch-normalization-for-training-of-deep-neural-networks.md)
    +   [配置反向传播来训练更好的神经网络的 8 个技巧](docs/dlperf/best-advice-for-configuring-backpropagation-for-deep-learning-neural-networks.md)
    +   [如何获得更好的深度学习效果（7 天迷你课程）](docs/dlperf/better-deep-learning-neural-networks-crash-course.md)
    +   [3 本深度学习实践者必备书籍](docs/dlperf/books-for-deep-learning-practitioners.md)
    +   [用于深度神经网络正则化的丢弃法的温和介绍](docs/dlperf/dropout-for-regularizing-deep-neural-networks.md)
    +   [避免过度训练神经网络的提前停止的温和介绍](docs/dlperf/early-stopping-to-avoid-overtraining-neural-network-models.md)
    +   [深度学习神经网络的集成学习方法](docs/dlperf/ensemble-methods-for-deep-learning-neural-networks.md)
    +   [更好的深度学习框架](docs/dlperf/framework-for-better-deep-learning.md)
    +   [如何在深度学习神经网络中使用贪婪逐层预训练](docs/dlperf/greedy-layer-wise-pretraining-tutorial.md)
    +   [如何开发水平投票深度学习集成来减少方差](docs/dlperf/horizontal-voting-ensemble.md)
    +   [如何利用批量归一化加速深度神经网络的学习](docs/dlperf/how-to-accelerate-learning-of-deep-neural-networks-with-batch-normalization.md)
    +   [如何避免梯度裁剪带来的梯度爆炸](docs/dlperf/how-to-avoid-exploding-gradients-in-neural-networks-with-gradient-clipping.md)
    +   [训练深度学习神经网络时如何选择损失函数](docs/dlperf/how-to-choose-loss-functions-when-training-deep-learning-neural-networks.md)
    +   [如何配置神经网络的层数和节点数](docs/dlperf/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network.md)
    +   [如何使用节点和层控制神经网络模型容量](docs/dlperf/how-to-control-neural-network-model-capacity-with-nodes-and-layers.md)
    +   [如何使用批量大小控制神经网络训练的稳定性](docs/dlperf/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size.md)
    +   [如何在 Keras 中创建深度学习模型的装袋集成](docs/dlperf/how-to-create-a-random-split-cross-validation-and-bagging-ensemble-for-deep-learning-in-keras.md)
    +   [如何通过深度学习展示自己的基本功](docs/dlperf/how-to-demonstrate-basic-deep-learning-competence.md)
    +   [如何使用 ReLU 修复梯度消失问题](docs/dlperf/how-to-fix-vanishing-gradients-using-the-rectified-linear-activation-function.md)
    +   [如何通过添加噪声来提高深度学习模型的鲁棒性](docs/dlperf/how-to-improve-deep-learning-model-robustness-by-adding-noise.md)
    +   [如何使用数据缩放提高深度学习模型的稳定性和表现](docs/dlperf/how-to-improve-neural-network-stability-and-modeling-performance-with-data-scaling.md)
    +   [如何利用迁移学习来提高深度学习神经网络的表现](docs/dlperf/how-to-improve-performance-with-transfer-learning-for-deep-learning-neural-networks.md)
    +   [如何利用 Keras 中的活动正则化减少泛化误差](docs/dlperf/how-to-reduce-generalization-error-in-deep-neural-networks-with-activity-regularization-in-keras.md)
    +   [如何在 Keras 中利用权重衰减减少神经网络的过拟合](docs/dlperf/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization.md)
    +   [如何在 Keras 中利用权重约束减少过拟合](docs/dlperf/how-to-reduce-overfitting-in-deep-neural-networks-with-weight-constraints-in-keras.md)
    +   [如何在 Keras 中利用丢弃正则化减少过拟合](docs/dlperf/how-to-reduce-overfitting-with-dropout-regularization-in-keras.md)
    +   [适时使用提前停止来停止神经网络的训练](docs/dlperf/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping.md)
    +   [数据集大小对深度学习模型技巧和表现评估的影响](docs/dlperf/impact-of-dataset-size-on-deep-learning-model-skill-and-performance-estimates.md)
    +   [如何提高深度学习表现](docs/dlperf/improve-deep-learning-performance.md)
    +   [如何避免深度学习神经网络中的过拟合](docs/dlperf/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error.md)
    +   [深度学习中权重限制的温和介绍](docs/dlperf/introduction-to-weight-constraints-to-reduce-generalization-error-in-deep-learning.md)
    +   [如何利用学习曲线诊断机器学习模型表现](docs/dlperf/learning-curves-for-diagnosing-machine-learning-model-performance.md)
    +   [训练深度学习神经网络时如何配置学习率](docs/dlperf/learning-rate-for-deep-learning-neural-networks.md)
    +   [用于训练深度学习神经网络的损失和损失函数](docs/dlperf/loss-and-loss-functions-for-training-deep-learning-neural-networks.md)
    +   [如何在 Keras 开发深度学习模型集成](docs/dlperf/model-averaging-ensemble-for-deep-learning-neural-networks.md)
    +   [神经网络诀窍（书评）](docs/dlperf/neural-networks-tricks-of-the-trade-review.md)
    +   [在 Keras 中集成神经网络模型权重（Polyak 平均）](docs/dlperf/polyak-neural-network-model-weight-ensemble.md)
    +   [深度学习神经网络从业者推荐](docs/dlperf/recommendations-for-deep-learning-neural-network-practitioners.md)
    +   [整流线性单元的温和介绍](docs/dlperf/rectified-linear-activation-function-for-deep-learning-neural-networks.md)
    +   [Python 中深度学习神经网络的快照集成](docs/dlperf/snapshot-ensemble-deep-learning-neural-network.md)
    +   [Python 中深度学习神经网络的堆叠集成](docs/dlperf/stacking-ensemble-for-deep-learning-neural-networks.md)
    +   [使用噪声训练神经网络来减少过拟合](docs/dlperf/train-neural-networks-with-noise-to-reduce-overfitting.md)
    +   [了解学习率对神经网络表现的影响](docs/dlperf/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks.md)
    +   [可视化梯度消失问题](docs/dlperf/visualizing-the-vanishing-gradient-problem.md)
    +   [使用权重正则化减少深度学习模型的过拟合](docs/dlperf/weight-regularization-to-reduce-overfitting-of-deep-learning-models.md)
    +   [如何为深度学习神经网络开发加权平均集成](docs/dlperf/weighted-average-ensemble-for-deep-learning-neural-networks.md)
    +   [为什么训练神经网络很难](docs/dlperf/why-training-a-neural-network-is-hard.md)
+   [Machine Learning Mastery 集成学习教程](docs/ensemble/README.md)
    +   [如何用 Python 开发 AdaBoost 集成](docs/ensemble/adaboost-ensemble-in-python.md)
    +   [使用不同数据转换开发装袋集成](docs/ensemble/bagging-ensemble-with-different-data-transformations.md)
    +   [如何用 Python 开发装袋集成](docs/ensemble/bagging-ensemble-with-python.md)
    +   [使用 Python 的混合集成机器学习](docs/ensemble/blending-ensemble-machine-learning-with-python.md)
    +   [如何组合集成学习的预测](docs/ensemble/combine-predictions-for-ensemble-learning.md)
    +   [Python 中的动态分类器选择集成](docs/ensemble/dynamic-classifier-selection-in-python.md)
    +   [Python 中用于分类的动态集成选择(DES)](docs/ensemble/dynamic-ensemble-selection-in-python.md)
    +   [机器学习集成多样性的温和介绍](docs/ensemble/ensemble-diversity-for-machine-learning.md)
    +   [集成学习算法复杂度和奥卡姆剃刀](docs/ensemble/ensemble-learning-and-occams-razor.md)
    +   [6 本集成学习书籍](docs/ensemble/ensemble-learning-books.md)
    +   [Python 集成机器学习（7 天迷你课程）](docs/ensemble/ensemble-machine-learning-with-python-7-day-mini-course.md)
    +   [机器学习的纠错输出码（ECOC）](docs/ensemble/error-correcting-output-codes-ecoc-for-machine-learning.md)
    +   [机器学习提升集成的本质](docs/ensemble/essence-of-boosting-ensembles-for-machine-learning.md)
    +   [自举聚合集成的本质](docs/ensemble/essence-of-bootstrap-aggregation-ensembles.md)
    +   [机器学习堆叠集成的本质](docs/ensemble/essence-of-stacking-ensembles-for-machine-learning.md)
    +   [如何使用 Python 开发额外树集合](docs/ensemble/extra-trees-ensemble-with-python.md)
    +   [Python 中的极限梯度提升（XGBoost）集成](docs/ensemble/extreme-gradient-boosting-ensemble-in-python.md)
    +   [如何在 Python 中开发特征选择子空间集成](docs/ensemble/feature-selection-subspace-ensemble-in-python.md)
    +   [如何在 Python 中开发梯度提升机集成](docs/ensemble/gradient-boosting-machine-ensemble-in-python.md)
    +   [将 Sklearn、XGBoost、LightGBM 和 CatBoost 用于梯度提升](docs/ensemble/gradient-boosting-with-scikit-learn-xgboost-lightgbm-and-catboost.md)
    +   [Python 中的生长和修剪集成](docs/ensemble/growing-and-pruning-ensembles-in-python.md)
    +   [Python 中基于直方图的梯度提升集成](docs/ensemble/histogram-based-gradient-boosting-ensembles.md)
    +   [开发对集成学习如何工作的直觉](docs/ensemble/how-ensemble-learning-works.md)
    +   [如何开轻量梯度提升机（LightGBM）集合](docs/ensemble/light-gradient-boosted-machine-lightgbm-ensemble.md)
    +   [什么是机器学习中的元学习？](docs/ensemble/meta-learning-in-machine-learning.md)
    +   [混合专家集成的温和介绍](docs/ensemble/mixture-of-experts.md)
    +   [如何用 Python 开发多输出回归模型](docs/ensemble/multi-output-regression-models-with-python.md)
    +   [多模型机器学习入门](docs/ensemble/multiple-model-machine-learning.md)
    +   [Python 中的多元自适应回归样条（MARS）](docs/ensemble/multivariate-adaptive-regression-splines-mars-in-python.md)
    +   [多类分类的一对一和一对剩余](docs/ensemble/one-vs-rest-and-one-vs-one-for-multi-class-classification.md)
    +   [如何在机器学习中使用折外预测](docs/ensemble/out-of-fold-predictions-in-machine-learning.md)
    +   [如何用 Python 开发随机森林集成](docs/ensemble/random-forest-ensemble-in-python.md)
    +   [如何用 XGBoost 开发随机森林集成](docs/ensemble/random-forest-ensembles-with-xgboost.md)
    +   [如何用 Python 开发随机子空间集成](docs/ensemble/random-subspace-ensemble-with-python.md)
    +   [使用 Python 开发堆叠集成机器学习](docs/ensemble/stacking-ensemble-machine-learning-with-python.md)
    +   [集成学习中强学习器与弱学习器](docs/ensemble/strong-learners-vs-weak-learners-for-ensemble-learning.md)
    +   [如何在 Python 中开发超级学习器集成](docs/ensemble/super-learner-ensemble-in-python.md)
    +   [集成学习算法的温和介绍](docs/ensemble/tour-of-ensemble-learning-algorithms.md)
    +   [如何用 Python 开发投票集成](docs/ensemble/voting-ensembles-with-python.md)
    +   [如何用 Python 开发加权平均集成](docs/ensemble/weighted-average-ensemble-with-python.md)
    +   [集成学习入门](docs/ensemble/what-is-ensemble-learning.md)
    +   [为什么使用集成学习？](docs/ensemble/why-use-ensemble-learning.md)
+   [Machine Learning Mastery 生成对抗网络教程](docs/gan/README.md)
    +   [Pix2Pix 生成对抗网络的温和介绍](docs/gan/a-gentle-introduction-to-pix2pix-generative-adversarial-network.md)
    +   [大型生成对抗网络 BigGAN 的温和介绍](docs/gan/a-gentle-introduction-to-the-biggan.md)
    +   [9 本关于生成对抗网络的书](docs/gan/books-on-generative-adversarial-networks-gans.md)
    +   [如何用 Keras 开发用于图像到图像转换的 CycleGAN](docs/gan/cyclegan-tutorial-with-keras.md)
    +   [生成对抗性网络损失函数的温和介绍](docs/gan/generative-adversarial-network-loss-functions.md)
    +   [如何从零开始开发 Wasserstein 生成对抗网络](docs/gan/how-to-code-a-wasserstein-generative-adversarial-network-wgan-from-scratch.md)
    +   [如何在 Keras 中实现 GAN Hacks 来训练稳定模型](docs/gan/how-to-code-generative-adversarial-network-hacks.md)
    +   [如何编写 GAN 训练算法和损失函数](docs/gan/how-to-code-the-generative-adversarial-network-training-algorithm-and-loss-functions.md)
    +   [如何从头开发一个条件 GAN（CGAN）](docs/gan/how-to-develop-a-conditional-generative-adversarial-network-from-scratch.md)
    +   [如何在 Keras 从零开始开发 1D 生成对抗网络](docs/gan/how-to-develop-a-generative-adversarial-network-for-a-1-dimensional-function-from-scratch-in-keras.md)
    +   [如何开发 GAN 来生成 CIFAR10 小型彩色照片](docs/gan/how-to-develop-a-generative-adversarial-network-for-a-cifar-10-small-object-photographs-from-scratch.md)
    +   [如何开发 GAN 来生成 MNIST 手写数字](docs/gan/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras.md)
    +   [如何开发用于图像到图像转换的 Pix2Pix GAN](docs/gan/how-to-develop-a-pix2pix-gan-for-image-to-image-translation.md)
    +   [如何用 Keras 从零开始开发辅助分类器 GAN(AC-GAN)](docs/gan/how-to-develop-an-auxiliary-classifier-gan-ac-gan-from-scratch-with-keras.md)
    +   [如何在 Keras 开发信息最大化 GAN（InfoGAN）](docs/gan/how-to-develop-an-information-maximizing-generative-adversarial-network-infogan-in-keras.md)
    +   [如何用 Keras 从零开始实现 CycleGAN 模型](docs/gan/how-to-develop-cyclegan-models-from-scratch-with-keras.md)
    +   [如何评估生成对抗网络](docs/gan/how-to-evaluate-generative-adversarial-networks.md)
    +   [如何入门生成对抗网络（7 天小型课程）](docs/gan/how-to-get-started-with-generative-adversarial-networks-7-day-mini-course.md)
    +   [如何用 Keras 从零开始实现 Pix2Pix GAN 模型](docs/gan/how-to-implement-pix2pix-gan-models-from-scratch-with-keras.md)
    +   [如何在 Keras 中实现渐进式增长 GAN 模型](docs/gan/how-to-implement-progressive-growing-gan-models-in-keras.md)
    +   [如何实现评估 GANs 的 Frechet 初始距离](docs/gan/how-to-implement-the-frechet-inception-distance-fid-from-scratch.md)
    +   [如何实现评估 GANs 的初始得分](docs/gan/how-to-implement-the-inception-score-from-scratch-for-evaluating-generated-images.md)
    +   [如何实现生成对抗网络的 Wasserstein 损失](docs/gan/how-to-implement-wasserstein-loss-for-generative-adversarial-networks.md)
    +   [如何在生成人脸时探索 GAN 潜在空间](docs/gan/how-to-interpolate-and-perform-vector-arithmetic-with-faces-using-a-generative-adversarial-network.md)
    +   [如何在 Keras 训练一个渐进式增长的 GAN 来合成人脸](docs/gan/how-to-train-a-progressive-growing-gan-in-keras-for-synthesizing-faces.md)
    +   [训练稳定生成对抗网络的技巧](docs/gan/how-to-train-stable-generative-adversarial-networks.md)
    +   [生成对抗网络的 18 个令人印象深刻的应用](docs/gan/impressive-applications-of-generative-adversarial-networks.md)
    +   [渐进式增长 GAN 的温和介绍](docs/gan/introduction-to-progressive-growing-generative-adversarial-networks.md)
    +   [StyleGAN 的温和介绍——风格生成对抗网络](docs/gan/introduction-to-style-generative-adversarial-network-stylegan.md)
    +   [如何在 Keras 开发最小二乘生成对抗网络](docs/gan/least-squares-generative-adversarial-network.md)
    +   [如何识别和诊断 GAN 故障模式](docs/gan/practical-guide-to-gan-failure-modes.md)
    +   [开始使用 GANs 的最佳资源](docs/gan/resources-for-getting-started-with-generative-adversarial-networks.md)
    +   [如何在 Keras 中从头实现半监督 GAN（SGAN）](docs/gan/semi-supervised-generative-adversarial-network.md)
    +   [生成对抗网络模型之旅](docs/gan/tour-of-generative-adversarial-network-models.md)
    +   [如何在 Keras 中使用 UpSampling2D 和 Conv2D 转置层](docs/gan/upsampling-and-transpose-convolution-layers-for-generative-adversarial-networks.md)
    +   [生成对抗网络（GANs）的温和介绍](docs/gan/what-are-generative-adversarial-networks-gans.md)
    +   [CycleGAN 图像转换的温和介绍](docs/gan/what-is-cyclegan.md)
+   [Machine Learning Mastery 不平衡数据教程](docs/imba/README.md)
    +   [用于不平衡分类的装袋和随机森林](docs/imba/bagging-and-random-forest-for-imbalanced-classification.md)
    +   [如何为不平衡分类结合过采样和欠采样](docs/imba/combine-oversampling-and-undersampling-for-imbalanced-classification.md)
    +   [用于不平衡分类的成本敏感决策树](docs/imba/cost-sensitive-decision-trees-for-imbalanced-classification.md)
    +   [不平衡分类的成本敏感学习](docs/imba/cost-sensitive-learning-for-imbalanced-classification.md)
    +   [不平衡分类的成本敏感逻辑回归](docs/imba/cost-sensitive-logistic-regression.md)
    +   [如何为不平衡分类开发成本敏感的神经网络](docs/imba/cost-sensitive-neural-network-for-imbalanced-classification.md)
    +   [用于不平衡分类的成本敏感 SVM](docs/imba/cost-sensitive-svm-for-imbalanced-classification.md)
    +   [如何为不平衡分类修复 K 折交叉验证](docs/imba/cross-validation-for-imbalanced-classification.md)
    +   [不平衡类别的数据采样方法之旅](docs/imba/data-sampling-methods-for-imbalanced-classification.md)
    +   [不平衡类别分布的分类准确率故障](docs/imba/failure-of-accuracy-for-imbalanced-class-distributions.md)
    +   [机器学习的 Fbeta 测量的温和介绍](docs/imba/fbeta-measure-for-machine-learning.md)
    +   [不平衡分类项目的分步框架](docs/imba/framework-for-imbalanced-classification-projects.md)
    +   [如何为乳腺癌患者存活建立概率模型](docs/imba/how-to-develop-a-probabilistic-model-of-breast-cancer-patient-survival.md)
    +   [开发严重偏斜的类分布的直觉](docs/imba/how-to-develop-an-intuition-skewed-class-distributions.md)
    +   [不平衡分类为什么难？](docs/imba/imbalanced-classification-is-hard.md)
    +   [检测乳腺摄影微钙化的不平衡分类模型](docs/imba/imbalanced-classification-model-to-detect-microcalcifications.md)
    +   [如何开发不平衡分类模型来检测漏油](docs/imba/imbalanced-classification-model-to-detect-oil-spills.md)
    +   [开发信用好坏的不平衡分类模型](docs/imba/imbalanced-classification-of-good-and-bad-credit.md)
    +   [Python 不平衡分类（7 天迷你课程）](docs/imba/imbalanced-classification-with-python-7-day-mini-course.md)
    +   [成人收入数据集的不平衡分类](docs/imba/imbalanced-classification-with-the-adult-income-dataset.md)
    +   [欺诈性信用卡交易数据集的不平衡分类](docs/imba/imbalanced-classification-with-the-fraudulent-credit-card-transactions-dataset.md)
    +   [大肠杆菌数据集的不平衡多类分类](docs/imba/imbalanced-multiclass-classification-with-the-e-coli-dataset.md)
    +   [玻璃识别数据集的不平衡多类分类](docs/imba/imbalanced-multiclass-classification-with-the-glass-identification-dataset.md)
    +   [多类不平衡分类](docs/imba/multi-class-imbalanced-classification.md)
    +   [每个不平衡分类度量的朴素分类器是什么？](docs/imba/naive-classifiers-imbalanced-classification-metrics.md)
    +   [不平衡数据集的单类分类算法](docs/imba/one-class-classification-algorithms.md)
    +   [如何计算不平衡分类的准确率、召回率和 F-Measure](docs/imba/precision-recall-and-f-measure-for-imbalanced-classification.md)
    +   [音素不平衡类别数据集的预测模型](docs/imba/predictive-model-for-the-phoneme-imbalanced-classification-dataset.md)
    +   [如何校准不平衡分类的概率](docs/imba/probability-calibration-for-imbalanced-classification.md)
    +   [不平衡分类概率度量的温和介绍](docs/imba/probability-metrics-for-imbalanced-classification.md)
    +   [用于不平衡分类的随机过采样和欠采样](docs/imba/random-oversampling-and-undersampling-for-imbalanced-classification.md)
    +   [不平衡分类的最佳资源](docs/imba/resources-for-imbalanced-classification.md)
    +   [不平衡分类的 ROC 曲线和精确率召回率曲线](docs/imba/roc-curves-and-precision-recall-curves-for-imbalanced-classification.md)
    +   [Python 中用于不平衡分类的 SMOTE](docs/imba/smote-oversampling-for-imbalanced-classification.md)
    +   [不平衡分类的标准机器学习数据集](docs/imba/standard-machine-learning-datasets-for-imbalanced-classification.md)
    +   [用于不平衡分类的阈值移动的温和介绍](docs/imba/threshold-moving-for-imbalanced-classification.md)
    +   [不平衡分类的评估指标之旅](docs/imba/tour-of-evaluation-metrics-for-imbalanced-classification.md)
    +   [不平衡分类的欠采样算法](docs/imba/undersampling-algorithms-for-imbalanced-classification.md)
    +   [不平衡分类的温和介绍](docs/imba/what-is-imbalanced-classification.md)
    +   [如何为不平衡分类配置 XGBoost](docs/imba/xgboost-for-imbalanced-classification.md)
+   [Machine Learning Mastery 优化教程](docs/optim/README.md)
    +   [用于函数优化的一维测试函数](docs/optim/1d-test-functions-for-function-optimization.md)
    +   [用于函数优化的二维测试函数](docs/optim/2d-test-functions-for-function-optimization.md)
    +   [粒子群优化的温和介绍](docs/optim/a-gentle-introduction-to-particle-swarm-optimization.md)
    +   [从零开始编写 Adam 优化算法](docs/optim/adam-optimization-from-scratch.md)
    +   [Python 中的盆地跳跃优化](docs/optim/basin-hopping-optimization-in-python.md)
    +   [BFGS 优化算法的温和介绍](docs/optim/bfgs-optimization-in-python.md)
    +   [遗传编程书籍](docs/optim/books-on-genetic-programming.md)
    +   [3 本机器学习优化书籍](docs/optim/books-on-optimization-for-machine-learning.md)
    +   [Python 曲线拟合](docs/optim/curve-fitting-with-python.md)
    +   [Python 中从零开始的差分进化](docs/optim/differential-evolution-from-scratch-in-python.md)
    +   [Python 差分进化的全局优化](docs/optim/differential-evolution-global-optimization-with-python.md)
    +   [Python 双重退火优化](docs/optim/dual-annealing-optimization-with-python.md)
    +   [Python 中从零开始的进化策略](docs/optim/evolution-strategies-from-scratch-in-python.md)
    +   [使用随机优化算法的特征选择](docs/optim/feature-selection-with-optimization.md)
    +   [使用 SciPy 的函数优化](docs/optim/function-optimization-with-scipy.md)
    +   [如何从零开始实现梯度下降优化](docs/optim/gradient-descent-optimization-from-scratch.md)
    +   [从零开始的 AdaMax 梯度下降优化](docs/optim/gradient-descent-optimization-with-adamax-from-scratch.md)
    +   [从零开始的 AMSGrad 梯度下降优化](docs/optim/gradient-descent-optimization-with-amsgrad-from-scratch.md)
    +   [从零开始的 Nadam 梯度下降优化](docs/optim/gradient-descent-optimization-with-nadam-from-scratch.md)
    +   [从零开始的 Adadelta 梯度下降](docs/optim/gradient-descent-with-adadelta-from-scratch.md)
    +   [从零开始的 AdaGrad 梯度下降](docs/optim/gradient-descent-with-adagrad-from-scratch.md)
    +   [从零开始的动量梯度下降](docs/optim/gradient-descent-with-momentum-from-scratch.md)
    +   [从零开始的 Nesterov 动量梯度下降](docs/optim/gradient-descent-with-nesterov-momentum-from-scratch.md)
    +   [从零开始的 RMSProp 梯度下降](docs/optim/gradient-descent-with-rmsprop-from-scratch.md)
    +   [什么是机器学习中的梯度？](docs/optim/gradient-in-machine-learning.md)
    +   [如何在 Python 中使用 NelderMead 优化](docs/optim/how-to-use-nelder-mead-optimization-in-python.md)
    +   [函数优化的温和介绍](docs/optim/introduction-to-function-optimization.md)
    +   [Python 中从零开始的迭代式局部搜索](docs/optim/iterated-local-search-from-scratch-in-python.md)
    +   [Python 线性搜索优化](docs/optim/line-search-optimization-with-python.md)
    +   [局部优化和全局优化的对比](docs/optim/local-optimization-versus-global-optimization.md)
    +   [如何手动优化机器学习模型超参数](docs/optim/manually-optimize-hyperparameters.md)
    +   [如何手动优化神经网络模型](docs/optim/manually-optimize-neural-networks.md)
    +   [使用 Sklearn 建模管道优化](docs/optim/modeling-pipeline-optimization-with-scikit-learn.md)
    +   [机器学习没有免费午餐定理](docs/optim/no-free-lunch-theorem-for-machine-learning.md)
    +   [机器学习优化速成班](docs/optim/optimization-for-machine-learning-crash-course.md)
    +   [如何使用优化算法手动拟合回归模型](docs/optim/optimize-regression-models.md)
    +   [过早收敛的温和介绍](docs/optim/premature-convergence.md)
    +   [函数优化的随机搜索和网格搜索](docs/optim/random-search-and-grid-search-for-function-optimization.md)
    +   [Python 中从零开始的简单遗传算法](docs/optim/simple-genetic-algorithm-from-scratch-in-python.md)
    +   [Python 中从零开始的模拟退火](docs/optim/simulated-annealing-from-scratch-in-python.md)
    +   [Python 中从零开始的随机爬山](docs/optim/stochastic-hill-climbing-in-python-from-scratch.md)
    +   [随机优化算法的简单介绍](docs/optim/stochastic-optimization-for-machine-learning.md)
    +   [如何选择优化算法](docs/optim/tour-of-optimization-algorithms.md)
    +   [Python 中的单变量函数优化](docs/optim/univariate-function-optimization-in-python.md)
    +   [Python 中函数优化的可视化](docs/optim/visualization-for-function-optimization-in-python.md)
    +   [为什么优化在机器学习中很重要](docs/optim/why-optimization-is-important-in-machine-learning.md)
+   [Machine Learning Mastery 概率教程](docs/prob/README.md)
    +   [简评詹森不等式](docs/prob/a-gentle-introduction-to-jensens-inequality.md)
    +   [贝叶斯最优分类器的简单介绍](docs/prob/bayes-optimal-classifier.md)
    +   [机器学习贝叶斯定理的温和介绍](docs/prob/bayes-theorem-for-machine-learning.md)
    +   [如何在 Python 中从零开始开发朴素贝叶斯分类器](docs/prob/classification-as-conditional-probability-and-the-naive-bayes-algorithm.md)
    +   [机器学习的连续概率分布](docs/prob/continuous-probability-distributions-for-machine-learning.md)
    +   [机器学习交叉熵的温和介绍](docs/prob/cross-entropy-for-machine-learning.md)
    +   [机器学习的离散概率分布](docs/prob/discrete-probability-distributions-for-machine-learning.md)
    +   [如何计算机器学习的 KL 散度](docs/prob/divergence-between-probability-distributions.md)
    +   [如何在 Python 中使用经验分布函数](docs/prob/empirical-distribution-function-in-python.md)
    +   [期望最大化算法的温和介绍](docs/prob/expectation-maximization-em-algorithm.md)
    +   [如何开发联合概率、边缘概率和条件概率的直觉](docs/prob/how-to-calculate-joint-marginal-and-conditional-probability.md)
    +   [如何通过工作实例开发概率的直觉](docs/prob/how-to-develop-an-intuition-for-probability-with-worked-examples.md)
    +   [如何利用概率开发和评估朴素分类器策略](docs/prob/how-to-develop-and-evaluate-naive-classifier-strategies-using-probability.md)
    +   [机器学习的信息增益和互信息](docs/prob/information-gain-and-mutual-information.md)
    +   [贝叶斯信念网络的温和介绍](docs/prob/introduction-to-bayesian-belief-networks.md)
    +   [计算学习理论的温和介绍](docs/prob/introduction-to-computational-learning-theory.md)
    +   [使用工作实例开发贝叶斯定理的直觉](docs/prob/intuition-for-bayes-theorem-with-worked-examples.md)
    +   [对联合概率、边缘概率和条件概率的温和介绍](docs/prob/joint-marginal-and-conditional-probability-for-machine-learning.md)
    +   [最大似然估计线性回归的简单介绍](docs/prob/linear-regression-with-maximum-likelihood-estimation.md)
    +   [使用最大似然估计的逻辑回归入门](docs/prob/logistic-regression-with-maximum-likelihood-estimation.md)
    +   [马尔可夫链蒙特卡罗的温和介绍](docs/prob/markov-chain-monte-carlo-for-probability.md)
    +   [机器学习最大后验概率的温和介绍](docs/prob/maximum-a-posteriori-estimation.md)
    +   [蒙特卡罗采样的温和介绍](docs/prob/monte-carlo-sampling-for-probability.md)
    +   [使用 AIC、BIC 和 MDL 的概率模型选择](docs/prob/probabilistic-model-selection-measures.md)
    +   [概率密度估计的简单介绍](docs/prob/probability-density-estimation.md)
    +   [面向机器学习的概率（7 天迷你课程）](docs/prob/probability-for-machine-learning-7-day-mini-course.md)
    +   [机器学习中概率的入门资源](docs/prob/probability-resources-for-machine-learning.md)
    +   [随机在机器学习中意味着什么？](docs/prob/stochastic-in-machine-learning.md)
    +   [机器学习中不确定性的温和介绍](docs/prob/uncertainty-in-machine-learning.md)
    +   [概率分布的简单介绍](docs/prob/what-are-probability-distributions.md)
    +   [如何在 Python 中从头实现贝叶斯优化](docs/prob/what-is-bayesian-optimization.md)
    +   [信息熵的温和介绍](docs/prob/what-is-information-entropy.md)
    +   [机器学习最大似然估计的温和介绍](docs/prob/what-is-maximum-likelihood-estimation-in-machine-learning.md)
    +   [什么是概率？](docs/prob/what-is-probability.md)
    +   [为机器学习学习概率的 5 个理由](docs/prob/why-learn-probability-for-machine-learning.md)
+   [Machine Learning Mastery R 机器学习教程](docs/rml/README.md)
    +   [从乘客存活预测案例研究中获得的应用机器学习经验](docs/rml/applied-machine-learning-lessons-from-a-case-study-of-passenger-survival-prediction.md)
    +   [R 机器学习书籍](docs/rml/books-for-machine-learning-with-r.md)
    +   [用于应用预测建模的 Caret 包](docs/rml/caret-r-package-for-applied-predictive-modeling.md)
    +   [使用 Caret R 包比较模型并选择最佳方案](docs/rml/compare-models-and-select-the-best-using-the-caret-r-package.md)
    +   [在 R 中比较机器学习算法](docs/rml/compare-the-performance-of-machine-learning-algorithms-in-r.md)
    +   [R 中的凸优化](docs/rml/convex-optimization-in-r.md)
    +   [使用可视化更好地理解你在 R 中的数据（今天你可以使用的 10 个秘籍）](docs/rml/data-visualization-in-r.md)
    +   [将 Caret R 包用于数据可视化](docs/rml/data-visualization-with-the-caret-r-package.md)
    +   [使用描述性统计更好地理解你的 R 数据](docs/rml/descriptive-statistics-examples-with-r.md)
    +   [如何用 R 评估机器学习算法](docs/rml/evaluate-machine-learning-algorithms-with-r.md)
    +   [使用 caret 包选择特征](docs/rml/feature-selection-with-the-caret-r-package.md)
    +   [在 R 中保存并最终确定您的机器学习模型](docs/rml/finalize-machine-learning-models-in-r.md)
    +   [如何在 R 中开始机器学习（一个周末内获得结果）](docs/rml/get-started-in-machine-learning-with-r.md)
    +   [如何使用 Caret 包估计 R 中的模型准确率](docs/rml/how-to-estimate-model-accuracy-in-r-using-the-caret-package.md)
    +   [如何在 R 中入门机器学习算法](docs/rml/how-to-get-started-with-machine-learning-algorithms-in-r.md)
    +   [如何在 R 中加载机器学习数据](docs/rml/how-to-load-your-machine-learning-data-into-r.md)
    +   [如何将 R 用于机器学习](docs/rml/how-to-use-r-for-machine-learning.md)
    +   [R 中的线性分类](docs/rml/linear-classification-in-r.md)
    +   [R 中的线性回归](docs/rml/linear-regression-in-r.md)
    +   [R 中的机器学习数据集（你现在可以使用的 10 个数据集）](docs/rml/machine-learning-datasets-in-r.md)
    +   [如何在 R 中构建机器学习算法的集成](docs/rml/machine-learning-ensembles-with-r.md)
    +   [R 中的机器学习评估指标](docs/rml/machine-learning-evaluation-metrics-in-r.md)
    +   [R 中的第一个机器学习逐步项目](docs/rml/machine-learning-in-r-step-by-step.md)
    +   [R 中的机器学习项目模板](docs/rml/machine-learning-project-template-in-r.md)
    +   [R 中的决策树非线性分类](docs/rml/non-linear-classification-in-r-with-decision-trees.md)
    +   [R 中的非线性分类](docs/rml/non-linear-classification-in-r.md)
    +   [R 中的决策树非线性回归](docs/rml/non-linear-regression-in-r-with-decision-trees.md)
    +   [R 中的非线性回归](docs/rml/non-linear-regression-in-r.md)
    +   [R 中的惩罚回归](docs/rml/penalized-regression-in-r.md)
    +   [通过预处理为机器学习准备好数据](docs/rml/pre-process-your-dataset-in-r.md)
    +   [R 的超快速成班（面向开发者）](docs/rml/r-crash-course-for-developers.md)
    +   [R 机器学习迷你课程](docs/rml/r-machine-learning-mini-course.md)
    +   [R 机器学习回顾](docs/rml/review-of-machine-learning-with-r.md)
    +   [抽查 R 中的机器学习算法（下一个项目要尝试的算法）](docs/rml/spot-check-machine-learning-algorithms-in-r.md)
    +   [调整 R 中的机器学习算法（随机森林案例研究）](docs/rml/tune-machine-learning-algorithms-in-r.md)
    +   [使用 Caret 包调整机器学习模型](docs/rml/tuning-machine-learning-models-using-the-caret-r-package.md)
    +   [将 R 用于机器学习](docs/rml/use-r-for-machine-learning.md)
    +   [什么是 R](docs/rml/what-is-r.md)
+   [Machine Learning Mastery Weka 教程](docs/weka/README.md)
    +   [Weka 机器学习迷你课程](docs/weka/applied-machine-learning-weka-mini-course.md)
    +   [使用 Weka 加快应用机器学习的进度](docs/weka/applied-machine-learning-with-weka.md)
    +   [如何在 Weka 中更好地理解你的机器学习数据](docs/weka/better-understand-machine-learning-data-weka.md)
    +   [我开始机器学习时犯的最大错误，以及如何避免](docs/weka/biggest-mistake-i-made-when-starting-machine-learning-and-how-to-avoid-it.md)
    +   [如何在 Weka 中逐步完成二分类项目](docs/weka/binary-classification-tutorial-weka.md)
    +   [案例研究：预测五年内糖尿病的发作（第 1 部分，共 3 部分）](docs/weka/case-study-predicting-the-onset-of-diabetes-within-five-years-part-1-of-3.md)
    +   [案例研究：预测五年内糖尿病的发作（第 2 部分，共 3 部分）](docs/weka/case-study-predicting-the-onset-of-diabetes-within-five-years-part-2-of-3.md)
    +   [案例研究：预测五年内糖尿病的发作（第 3 部分，共 3 部分）](docs/weka/case-study-predicting-the-onset-of-diabetes-within-five-years-part-3-of-3.md)
    +   [如何在 Weka 中比较机器学习算法的表现](docs/weka/compare-performance-machine-learning-algorithms-weka.md)
    +   [设计并运行你在 Weka 的第一个实验](docs/weka/design-and-run-your-first-experiment-in-weka.md)
    +   [如何下载安装 Weka 机器学习工作台](docs/weka/download-install-weka-machine-learning-workbench.md)
    +   [如何在 Weka 中评估机器学习模型的基线表现](docs/weka/estimate-baseline-performance-machine-learning-models-weka.md)
    +   [如何在 Weka 中估计机器学习算法的表现](docs/weka/estimate-performance-machine-learning-algorithms-weka.md)
    +   [用于提高准确率和减少训练时间的特征选择](docs/weka/feature-selection-to-improve-accuracy-and-decrease-training-time.md)
    +   [如何获得更多 Weka 机器学习工作台的帮助](docs/weka/help-with-weka.md)
    +   [如何使用 Weka 处理机器学习数据中的缺失值](docs/weka/how-to-handle-missing-values-in-machine-learning-data-with-weka.md)
    +   [如何在 Weka 中运行你的第一个分类器](docs/weka/how-to-run-your-first-classifier-in-weka.md)
    +   [如何在 Weka 中调整机器学习算法](docs/weka/how-to-tune-a-machine-learning-algorithm-in-weka.md)
    +   [在 Weka 中为更好的预测使用提升、装袋和混合集成](docs/weka/improve-machine-learning-results-with-boosting-bagging-and-blending-ensemble-methods-in-weka.md)
    +   [如何在 Weka 中加载 CSV 机器学习数据](docs/weka/load-csv-machine-learning-data-weka.md)
    +   [使用关联规则学习的菜篮子分析](docs/weka/market-basket-analysis-with-association-rule-learning.md)
    +   [如何在 Weka 完成多类分类项目](docs/weka/multi-class-classification-tutorial-weka.md)
    +   [如何在 Weka 中规范和标准化你的机器学习数据](docs/weka/normalize-standardize-machine-learning-data-weka.md)
    +   [如何在 Weka 中用机器学习数据执行特征选择](docs/weka/perform-feature-selection-machine-learning-data-weka.md)
    +   [针对机器学习问题的快速脏数据分析](docs/weka/quick-and-dirty-data-analysis-for-your-machine-learning-problem.md)
    +   [如何在 Weka 中浏览回归机器学习项目](docs/weka/regression-machine-learning-tutorial-weka.md)
    +   [如何保存你的机器学习模型并在 Weka 中做出预测](docs/weka/save-machine-learning-model-make-predictions-weka.md)
    +   [Weka 中用于练习的标准机器学习数据集](docs/weka/standard-machine-learning-datasets-used-practice-weka.md)
    +   [Weka 中解决机器学习问题的模板](docs/weka/template-for-working-through-machine-learning-problems-in-weka.md)
    +   [Weka 机器学习工作台之旅](docs/weka/tour-weka-machine-learning-workbench.md)
    +   [如何在 Weka 中转换你的机器学习数据](docs/weka/transform-machine-learning-data-weka.md)
    +   [如何在 Weka 中调整机器学习算法](docs/weka/tune-machine-learning-algorithms-weka.md)
    +   [如何在 Weka 中使用分类机器学习算法](docs/weka/use-classification-machine-learning-algorithms-weka.md)
    +   [如何在 Weka 中使用集成机器学习算法](docs/weka/use-ensemble-machine-learning-algorithms-weka.md)
    +   [如何在 Weka 中使用机器学习算法](docs/weka/use-machine-learning-algorithms-weka.md)
    +   [如何在 Weka 中使用回归机器学习算法](docs/weka/use-regression-machine-learning-algorithms-weka.md)
    +   [什么是 Weka 机器学习工作台](docs/weka/what-is-the-weka-machine-learning-workbench.md)
