# 如何组合集成学习的预测

> 原文：<https://machinelearningmastery.com/combine-predictions-for-ensemble-learning/>

最后更新于 2021 年 4 月 27 日

集合方法包括组合来自多个模型的预测。

预测的**组合**是集合方法的核心部分，并且在很大程度上取决于对集合有贡献的模型类型和正在建模的预测问题的类型，例如分类或回归。

尽管如此，仍有一些通用或标准的技术可用于组合预测，这些技术易于实现，通常会产生良好或最佳的预测表现。

在这篇文章中，您将发现组合集成学习预测的常用技术。

看完这篇文章，你会知道:

*   组合来自贡献模型的预测是集合模型的关键属性。
*   投票技术最常用于组合预测进行分类。
*   统计技术最常用于组合回归预测。

**用我的新书[Python 集成学习算法](https://machinelearningmastery.com/ensemble-learning-algorithms-with-python/)启动你的项目**，包括*分步教程*和所有示例的 *Python 源代码*文件。

我们开始吧。

![How to Combine Predictions for Ensemble Learning](img/f5437e09dc28b4c093774f3f436e25c7.png)

如何为集成学习组合预测
图片由 [cafuego](https://www.flickr.com/photos/cafuego/35846456894/) 提供，保留部分权利。

## 教程概述

本教程分为三个部分；它们是:

1.  集成学习中的组合预测
2.  组合分类预测
    1.  组合预测的类别标签
    2.  组合预测的类概率
3.  组合回归预测

## 集成学习中的组合预测

集成学习方法的一个关键部分包括组合来自多个模型的预测。

正是通过这些预测的组合，实现了集成学习方法的好处，即更好的预测表现。因此，有许多方法可以组合预测，以至于它是一个完整的研究领域。

> 在生成一组基础学习器之后，集成方法不是试图找到最佳的单个学习器，而是求助于组合来实现强大的泛化能力，其中组合方法起着至关重要的作用。

—第 67 页，[集合方法](https://amzn.to/2XZzrjG)，2012。

标准的集成机器学习算法确实规定了如何组合预测；然而，出于一些原因，必须孤立地考虑这一专题，例如:

*   解释由标准集合算法做出的预测。
*   为算法手动指定自定义预测组合方法。
*   发展你自己的集成方法。

集成学习方法通常不是很复杂，开发您自己的集成方法或指定组合预测的方式是相对容易和常见的做法。

组合预测的方式取决于进行预测的模型和预测问题的类型。

> 该步骤中使用的策略部分取决于用作集成成员的分类器的类型。例如，一些分类器，如支持向量机，只提供离散值的标签输出。

—第 6 页，[集成机器学习](https://amzn.to/2C7syo5)，2012。

例如，由模型做出的预测的形式将匹配预测问题的类型，例如用于预测数字的回归和用于预测类别标签的分类。此外，一些模型类型可能只能预测类别标签或类别概率分布，而其他模型类型可能能够支持分类任务的两者。

我们将使用这种基于问题类型的预测类型划分，作为探索用于在集合中组合来自贡献模型的预测的常用技术的基础。

在下一节中，我们将了解如何为分类预测建模任务组合预测。

## 组合分类预测

[分类](https://machinelearningmastery.com/types-of-classification-in-machine-learning/)是指预测建模问题，包括预测给定输入的类别标签。

由模型做出的预测可以是直接清晰的类标签，或者可以是一个示例属于每个类的概率，称为类成员的概率。

分类问题的表现通常使用准确性或相关计数或正确预测的比率来衡量。在评估预测概率的情况下，可以通过选择截止阈值将它们转换为清晰的类别标签，或者使用专门的度量来评估，例如[交叉熵](https://machinelearningmastery.com/cross-entropy-for-machine-learning/)。

我们将回顾分别为类别标签和概率组合分类预测。

### 组合预测的类别标签

预测的类标签通常被映射到对问题域有意义的东西。

例如，模型可以预测诸如“*红色*或“*绿色*的颜色”。不过，在内部，该模型预测类标签的数字表示，例如 0 代表“*红色*”，1 代表“*绿色*”，2 代表“*蓝色*”作为我们的颜色分类示例。

如果我们直接使用整数编码的类标签，组合类标签的方法可能更容易考虑。

也许最简单、最常见、通常也是最有效的方法是通过投票将预测结合起来。

> 投票是标称输出最流行和最基本的组合方法。

—第 71 页，[集合方法](https://amzn.to/2XZzrjG)，2012。

[投票](https://machinelearningmastery.com/voting-ensembles-with-python/)通常涉及做出预测的每个模型，为预测的类分配一个投票。计算选票，然后以某种方式使用选票或计票来选择结果。

投票有很多种类型，让我们来看看最常见的四种:

*   多数投票。
*   多数投票。
*   一致投票。
*   加权投票。

简单投票，称为**多数投票**，选择票数最多的班级标签。

如果两个或两个以上的班级拥有相同的票数，那么平局会被任意打破，尽管是以一致的方式，例如对有平局的班级标签进行排序并选择第一个，而不是随机选择一个。这一点很重要，这样，具有相同数据的相同模型总是做出相同的预测。

给定联系，通常会有奇数个集成成员试图自动断开联系，而偶数个集成成员可能更有可能断开联系。

从统计学的角度来看，这被称为模式或预测集合中最常见的值。

例如，考虑一个模型对三类颜色预测问题所做的三个预测:

*   模型 1 预测“*绿色*或 1。
*   模型 2 预测“*绿色*或 1。
*   模型 3 预测“*红色*或 0。

因此，投票结果如下:

*   红色票:1
*   绿色投票:2
*   蓝色选票:0

鉴于它拥有最多的选票，预测将是绿色的。

**多数票**选择得票超过半数的班级标签。如果没有一个班级拥有超过半数的选票，那么就产生了一个“*无预测*”。有趣的是，如果分类器是独立的，多数投票可以被证明是组合分类器的最佳方法。

> 如果分类器输出是独立的，那么可以证明多数投票是最优组合规则。

—第 1 页，[集成机器学习](https://amzn.to/2C7syo5)，2012。

**一致投票**与多数投票相关，因为该方法不需要一半的票数，而是要求所有模型预测相同的值，否则不做预测。

**加权投票**以某种方式对每个模型做出的预测进行加权。一个例子是根据模型的平均表现(如分类准确率)对预测进行加权。

> 每个分类器的权重可以设置成与其在验证集上的准确性表现成比例。

—第 67 页，[使用集成方法的模式分类](https://amzn.to/2zxc0F7)，2010。

给分类器分配权重本身可能成为一个项目，可能涉及使用优化算法和保持数据集、线性模型，甚至完全使用另一个机器学习模型。

> 那么，我们如何分配权重呢？如果我们事先知道哪些分类器会更好地工作，我们只会使用那些分类器。在缺乏此类信息的情况下，一种合理且常用的策略是使用分类器在单独验证(甚至训练)数据集上的表现，作为该分类器泛化表现的估计。

—第 8 页，[集成机器学习](https://amzn.to/2C7syo5)，2012。

加权投票的想法是，一些分类器比其他分类器更有可能准确，我们应该通过给他们更大份额的选票来奖励他们。

> 如果我们有理由相信某些分类器比其他分类器更有可能是正确的，那么与多数投票相比，对这些分类器的决策进行更重的加权可以进一步提高整体表现。

—第 7 页，[集成机器学习](https://amzn.to/2C7syo5)，2012。

### 组合预测的类概率

[概率](https://machinelearningmastery.com/how-to-develop-an-intuition-for-probability-with-worked-examples/)将事件的可能性总结为 0.0 到 1.0 之间的数值。

当预测类别成员资格时，它涉及为每个类别分配的概率，加起来等于值 1.0；例如，模型可以预测:

*   红色:0.75
*   绿色:0.10
*   蓝色:0.15

我们可以看到类“*红色*”具有最高的概率或者是模型预测的最可能的结果，并且类之间的概率分布(0.75 + 0.10 + 0.15)总和为 1.0。

概率的组合方式取决于所需的结果。

例如，如果需要概率，则可以直接组合独立的预测概率。

也许最简单的概率组合方法是将每个类的概率相加，并通过 softmax 函数传递预测值。这确保了分数被适当地标准化，这意味着类标签上的概率总和为 1.0。

> ……这样的输出——经过适当的标准化(如 softmax 标准化…])——可以解释为对该类的支持程度

—第 8 页，[集成机器学习](https://amzn.to/2C7syo5)，2012。

更常见的是，我们希望根据预测的概率来预测类别标签。

最常见的方法是使用投票，其中预测概率代表每个模型对每个类别的投票。然后对投票进行求和，可以使用上一节中的投票方法，例如选择具有最大求和概率或最大平均概率的标签。

*   使用平均概率投票
*   使用总和概率投票
*   使用加权和概率投票

通常，这种将概率视为选择类别标签的投票的方法被称为软投票。

> 如果所有的单个分类器被同等对待，简单软投票方法通过简单地平均所有的单个输出来产生组合输出…

—第 76 页，[集合方法](https://amzn.to/2XZzrjG)，2012。

## 组合回归预测

回归是指预测建模问题，包括预测给定输入的数值。

回归问题的表现通常使用平均误差来衡量，例如平均绝对误差或均方根误差。

组合数字预测通常涉及使用简单的统计方法；例如:

*   平均预测值
*   预测值中位数

两者都给出了预测分布的中心趋势。

> 求平均值是数字输出最流行和最基本的组合方法。

—第 68 页，[集合方法](https://amzn.to/2XZzrjG)，2012。

平均值也称为平均值，是预测值的归一化总和。当预测的分布是高斯或近似高斯时，平均预测值更合适。

例如，平均值计算为预测值之和除以预测总数。如果三个模型预测了以下价格:

*   型号 1: 99.00
*   型号 2: 101.00
*   型号 3: 98.00

预测的平均值计算如下:

*   平均预测= (99.00 + 101.00 + 98.00) / 3
*   平均预测= 298.00 / 3
*   平均预测= 99.33

> 由于简单有效，简单平均法是最常用的方法之一，在许多实际应用中是首选。

—第 69 页，[集合方法](https://amzn.to/2XZzrjG)，2012。

如果所有预测都是有序的，中位数是中间值，也称为第 50 个百分点。当预测的分布未知或不遵循高斯概率分布时，中值预测值更适合使用。

根据预测问题的性质，可能需要保守预测，例如最大值或最小值。此外，可以总结分布以给出不确定性的度量，例如为每个预测报告三个值:

*   最小预测值
*   预测值中位数
*   最大预测值

与分类一样，每个模型做出的预测可以通过预期的模型表现或其他值进行加权，并且可以报告预测的加权平均值。

## 进一步阅读

如果您想更深入地了解这个主题，本节将提供更多资源。

### 书

*   [使用集成方法的模式分类](https://amzn.to/2zxc0F7)，2010。
*   [集成方法](https://amzn.to/2XZzrjG)，2012。
*   [集成机器学习](https://amzn.to/2C7syo5)，2012。
*   [数据挖掘中的集成方法](https://amzn.to/3frGM1A)，2010。

### 文章

*   一起学习，维基百科。
*   [一起学习，学院派](http://www.scholarpedia.org/article/Ensemble_learning)。

## 摘要

在这篇文章中，您发现了组合集成学习预测的常用技术。

具体来说，您了解到:

*   组合来自贡献模型的预测是集合模型的关键属性。
*   投票技术最常用于组合预测进行分类。
*   统计技术最常用于组合回归预测。

**你有什么问题吗？**
在下面的评论中提问，我会尽力回答。