# 马尔可夫链蒙特卡罗的温和介绍

> 原文：<https://machinelearningmastery.com/markov-chain-monte-carlo-for-probability/>

概率推断包括使用概率模型估计期望值或密度。

通常，用概率模型直接推断数值是不容易的，相反，必须使用近似方法。

马尔可夫链蒙特卡罗采样提供了一类从高维概率分布中进行系统随机采样的算法。与能够从分布中抽取独立样本的蒙特卡罗采样方法不同，马尔可夫链蒙特卡罗方法抽取下一个样本依赖于现有样本的样本，称为马尔可夫链。这使得算法能够缩小分布的近似数量，即使有大量的随机变量。

在这篇文章中，你会发现一个关于机器学习的马尔可夫链蒙特卡罗的温和介绍。

看完这篇文章，你会知道:

*   蒙特卡罗采样是无效的，对于高维概率模型来说可能是难以处理的。
*   马尔可夫链蒙特卡罗提供了一种对高维概率分布进行随机采样的替代方法，其中下一个样本依赖于当前样本。
*   吉布斯采样和更一般的大都会-黑斯廷斯算法是马尔可夫链蒙特卡罗采样的两种最常见的方法。

**用我的新书[机器学习概率](https://machinelearningmastery.com/probability-for-machine-learning/)启动你的项目**，包括*分步教程*和所有示例的 *Python 源代码*文件。

我们开始吧。

![A Gentle Introduction to Markov Chain Monte Carlo for Probability](img/04f3c41d415c48956dd71285aaa25da4.png)

概率马尔可夫链蒙特卡罗的温和介绍[穆雷·富比斯特](https://www.flickr.com/photos/mfoubister/41582162705/)摄，版权所有。

## 概观

本教程分为三个部分；它们是:

1.  概率推理的挑战
2.  什么是马尔可夫链蒙特卡罗
3.  马尔可夫链蒙特卡罗算法

## 概率推理的挑战

从概率模型中计算一个量通常被称为概率推断，或简称为推断。

例如，我们可能对计算预期概率、估计密度或概率分布的其他属性感兴趣。这是概率模型的目标，并且所执行的推理的名称通常采用概率模型的名称，例如，贝叶斯推理是用贝叶斯概率模型来执行的。

从感兴趣的模型直接计算期望的量对于除了最普通的概率模型之外的所有模型都是难以处理的。相反，预期的概率或密度必须用其他方法来近似。

> 对于大多数实际感兴趣的概率模型，精确的推断是难以处理的，因此我们不得不求助于某种形式的近似。

—第 523 页，[模式识别与机器学习](https://amzn.to/2JwHE7I)，2006。

期望的计算通常是许多随机变量的离散分布的和或者许多变量的连续分布的积分，并且难以计算。这个问题在两个概率学派中都存在，尽管对于贝叶斯概率和对模型的后验分布进行积分可能更普遍或更常见。

> 贝叶斯主义者，有时也是常客，需要整合可能的高维概率分布来推断模型参数或进行预测。贝叶斯需要对给定数据的模型参数的后验分布进行积分，频繁者可能需要对给定参数值的可观测值的分布进行积分。

—第 1 页，[实践中的马尔可夫链蒙特卡罗](https://amzn.to/2KOElJX)，1996。

典型的解决方案是从概率分布中抽取独立的样本，然后多次重复这个过程来逼近期望的量。这被称为蒙特卡罗采样或蒙特卡罗积分，以摩纳哥拥有许多赌场的城市命名。

蒙特卡罗采样的问题是它在高维空间中不能很好地工作。这首先是因为维数灾难，其中样本空间的体积随着参数(维数)的数量呈指数增长。

其次，或许也是最关键的一点，这是因为蒙特卡罗采样假设从目标分布中抽取的每个随机样本都是独立的，并且可以独立抽取。对于贝叶斯结构化或图形概率模型的推理来说，情况通常不是这样，也不是很难处理。

## 什么是马尔可夫链蒙特卡罗

高维采样概率分布的解决方案是使用[马尔可夫链蒙特卡罗](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo)，简称 MCMC。

> 从高维分布中取样的最流行的方法是马尔可夫链蒙特卡罗或 MCMC

—第 837 页，[机器学习:概率视角](https://amzn.to/2xKSTCP)，2012。

像蒙特卡罗方法一样，马尔可夫链蒙特卡罗大约在第一批计算机开发的同时首次被开发出来，并被用于粒子物理的计算，这是开发原子弹的曼哈顿计划的一部分。

### 蒙地卡罗

[蒙特卡罗](https://en.wikipedia.org/wiki/Monte_Carlo_method)是一种随机采样概率分布并逼近期望量的技术。

> 蒙特卡洛算法。]在许多科学分支中用于估计难以精确计算的量。

—第 530 页，[人工智能:现代方法](https://amzn.to/2Y7yCpO)，第 3 版，2009 年。

蒙特卡罗方法通常假设我们可以有效地从目标分布中抽取样本。从抽取的样本中，我们可以估计出作为抽取样本的平均值或方差的和或积分量。

考虑蒙特卡罗采样过程的一个有用方法是考虑复杂的二维形状，例如螺旋。我们不能简单地定义一个函数来描述螺旋，但是我们可以从域中提取样本，并确定它们是否是螺旋的一部分。从该域中提取的大量样本将使我们能够总结螺旋的形状(概率密度)。

### 马尔可夫链

[马尔可夫链](https://en.wikipedia.org/wiki/Markov_chain)是一种生成随机变量序列的系统方法，其中当前值在概率上依赖于先前变量的值。具体来说，选择下一个变量只取决于链中的最后一个变量。

> 马尔可夫链是一种特殊的随机过程，它处理随机变量序列的特征。特别关注序列的动态和极限行为。

—第 113 页，[马尔可夫链蒙特卡罗:贝叶斯推理的随机模拟](https://amzn.to/31SRqaD)，2006。

考虑一个包含掷骰子的棋盘游戏，比如[蛇和梯子](https://en.wikipedia.org/wiki/Snakes_and_Ladders)(或者滑槽和梯子)。骰子的滚动在 6 个阶段(整数 1 到 6)具有均匀的概率分布。你在棋盘上有一个位置，但你在棋盘上的下一个位置仅基于当前位置和骰子的随机滚动。你在棋盘上的特定位置形成了一条马尔可夫链。

马尔可夫链的另一个例子是一维随机游走，其中可能的移动是 1，-1，以相等的概率选择，游走中数字线上的下一点仅取决于当前位置和随机选择的移动。

> 在高级别上，马尔可夫链是根据状态图来定义的，采样算法在状态图上进行随机游走。

—第 507 页，[概率图形模型:原理和技术](https://amzn.to/2Zjo7fF)，2009 年。

### 马尔可夫链蒙特卡罗

结合马尔可夫链和蒙特卡罗这两种方法，通过构建包含蒙特卡罗样本的马尔可夫链，允许对尊重样本之间概率相关性的高维概率分布进行随机采样。

> MCMC 本质上是使用马尔可夫链的蒙特卡罗积分。[……]蒙特卡罗积分从所需分布中抽取样本，然后形成样本平均值以逼近预期。马尔可夫链蒙特卡罗通过长时间运行一个巧妙构造的马尔可夫链来绘制这些样本。

—第 1 页，[实践中的马尔可夫链蒙特卡罗](https://amzn.to/2KOElJX)，1996。

具体来说，MCMC 用于对概率分布执行推断(例如，估计数量或密度)，其中不能从分布中提取独立样本，或者不能容易地提取独立样本。

因此，蒙特卡罗采样不能使用。

相反，通过构建马尔可夫链从概率分布中提取样本，其中从概率分布中提取的下一个样本取决于提取的最后一个样本。这个想法是，链条将会停留在(找到平衡)我们推断的期望量上。

然而，我们仍在从目标概率分布中进行采样，目标是逼近期望的数量，因此将所得的样本集合称为蒙特卡罗样本是合适的，例如，抽取的样本范围通常形成一个长马尔可夫链。

在样本之间强加依赖关系的想法起初看起来很奇怪，但如果我们考虑像[随机漫步](https://machinelearningmastery.com/gentle-introduction-random-walk-times-series-forecasting-python/)或蛇和梯子游戏这样的领域，其中样本之间的这种依赖关系是必需的，那么这个想法可能更有意义。

## 马尔可夫链蒙特卡罗算法

有许多马尔可夫链蒙特卡罗算法，在执行每个蒙特卡罗样本时，它们大多定义了不同的马尔可夫链构造方法。

随机游走为样本马尔可夫链的构建提供了一个很好的比喻，但它的效率非常低。考虑我们可能想要计算预期概率的情况；放大数量或密度比在域中徘徊更有效。马尔可夫链蒙特卡罗算法试图仔细利用问题的特性，以便有效地构建链。

> 构建该序列，使得尽管第一个样本可以从先前产生，但是连续的样本是从可证明越来越接近期望的后验的分布产生的。

—第 505 页，[概率图形模型:原理和技术](https://amzn.to/2Zjo7fF)，2009 年。

MCMC 算法对它们的起点很敏感，并且通常需要预热阶段或老化阶段来进入搜索空间中富有成效的部分，之后可以丢弃先前的样本并收集有用的样本。

此外，要知道一个链是否已经收敛并收集了足够多的步骤可能是一项挑战。通常需要非常大量的样品，并且在给定固定数量的步骤的情况下停止运行。

> ……有必要丢弃一些初始样本，直到马尔可夫链烧入或进入其平稳分布。

—第 838 页，[机器学习:概率视角](https://amzn.to/2xKSTCP)，2012。

最常见的通用马尔可夫链蒙特卡罗算法叫做吉布斯采样；这个采样器的一个更通用的版本叫做 Metropolis-Hastings 算法。

让我们仔细看看这两种方法。

### 吉布斯采样算法

[吉布斯采样](https://en.wikipedia.org/wiki/Gibbs_sampling)算法是一种构建马尔可夫链的方法，其中下一个样本的概率被计算为给定前一个样本的条件概率。

样本是通过一次改变一个随机变量来构造的，这意味着后续样本在搜索空间中非常接近，例如局部接近。因此，链条有卡住的风险。

> 吉布斯采样背后的思想是，我们依次对每个变量进行采样，条件是分布中所有其他变量的值。

—第 838 页，[机器学习:概率视角](https://amzn.to/2xKSTCP)，2012。

吉布斯采样适用于那些可以计算条件概率的概率模型，例如，分布是离散的而不是连续的。

> ……Gibbs 采样只适用于某些情况；特别是，我们必须能够从分布 P(Xi | x-i)中取样。虽然对于离散图形模型来说，这个采样步骤很容易，但是在连续模型中，条件分布可能不是具有允许采样的参数形式的分布，因此吉布斯不适用。

—第 515 页，[概率图形模型:原理和技术](https://amzn.to/2Zjo7fF)，2009 年。

### 大都会-黑斯廷斯算法

[Metropolis-Hastings 算法](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm)适用于那些我们无法直接对所谓的下一个状态概率分布进行采样的概率模型，比如 Gibbs Sampling 使用的条件概率分布。

> 与吉布斯链不同，该算法不假设我们可以从特定的目标分布生成下一状态样本。

—第 517 页，[概率图形模型:原理和技术](https://amzn.to/2Zjo7fF)，2009 年。

相反，Metropolis-Hastings 算法涉及使用被采样的替代或建议概率分布(有时称为核)，然后是决定新样本是被链接受还是被丢弃的接受标准。

> 它们基于马尔可夫链，其对前任的依赖分为两部分:提议和接受提议。提案建议在链条的轨迹中任意进行下一步，通过拒绝链条的不需要的移动，接受确保保持适当的限制方向。

—第 6 页，[马尔可夫链蒙特卡罗:贝叶斯推理的随机模拟](https://amzn.to/31SRqaD)，2006。

接受标准是概率性的，基于提议分布与真实的下一状态概率分布的不同程度。

Metropolis-Hastings 算法是一种更通用、更灵活的马尔可夫链蒙特卡罗算法，包含了许多其他方法。

例如，如果使用下一步条件概率分布作为建议分布，那么 Metropolis-Hastings 算法通常相当于 Gibbs 采样算法。如果像高斯分布一样使用对称建议分布，则该算法相当于另一种称为 Metropolis 算法的 MCMC 方法。

## 进一步阅读

如果您想更深入地了解这个主题，本节将提供更多资源。

### 书

*   [实践中的马尔可夫链蒙特卡罗](https://amzn.to/2KOElJX)，1996。
*   [马尔可夫链蒙特卡罗:贝叶斯推理的随机模拟](https://amzn.to/31SRqaD)，2006。
*   [马尔可夫链蒙特卡罗手册](https://amzn.to/2Zk5kRB)，2011。
*   [概率图形模型:原理和技术](https://amzn.to/2Zjo7fF)，2009。

### 章

*   第 24 章马尔可夫链蒙特卡罗(MCMC)推理，[机器学习:概率视角](https://amzn.to/2xKSTCP)，2012。
*   第 11.2 节。马尔可夫链蒙特卡罗，[模式识别和机器学习](https://amzn.to/2JwHE7I)，2006。
*   第 17.3 节马尔可夫链蒙特卡罗方法，[深度学习](https://amzn.to/2lnc3vL)，2016。

### 文章

*   [蒙特卡罗方法，维基百科](https://en.wikipedia.org/wiki/Monte_Carlo_method)。
*   [马尔可夫链，维基百科](https://en.wikipedia.org/wiki/Markov_chain)。
*   [马尔可夫链蒙特卡洛，维基百科](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo)。
*   [吉布斯采样，维基百科](https://en.wikipedia.org/wiki/Gibbs_sampling)。
*   [大都会–黑斯廷斯算法，维基百科](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm)。
*   [假人 MCMC 采样](https://twiecki.io/blog/2015/11/10/mcmc-sampling/)，2015 年。
*   [你会如何向外行解释马尔可夫链蒙特卡罗(MCMC)？](https://stats.stackexchange.com/questions/165/how-would-you-explain-markov-chain-monte-carlo-mcmc-to-a-layperson)

## 摘要

在这篇文章中，你发现了一个关于机器学习的马尔可夫链蒙特卡罗的温和介绍。

具体来说，您了解到:

*   蒙特卡罗采样是无效的，对于高维概率模型来说可能是难以处理的。
*   马尔可夫链蒙特卡罗提供了一种对高维概率分布进行随机采样的替代方法，其中下一个样本依赖于当前样本。
*   吉布斯采样和更一般的大都会-黑斯廷斯算法是马尔可夫链蒙特卡罗采样的两种最常见的方法。

你有什么问题吗？
在下面的评论中提问，我会尽力回答。