# 不平衡类别的数据采样方法之旅

> 原文：<https://machinelearningmastery.com/data-sampling-methods-for-imbalanced-classification/>

机器学习技术在具有不平衡类分布的类别数据集上经常失败或给出令人误解的乐观表现。

原因是，许多机器学习算法被设计成对类别数据进行操作，每个类具有相等数量的观察值。当情况并非如此时，算法可以了解到，为了获得良好的表现，极少数示例并不重要，可以忽略。

数据采样提供了一组转换训练数据集的技术，以便平衡或更好地平衡类分布。一旦平衡，标准的机器学习算法可以直接在转换后的数据集上训练，而无需任何修改。这允许用数据准备方法解决不平衡分类的挑战，即使是严重不平衡的类分布。

有许多不同类型的数据采样方法可以使用，并且没有单一的最佳方法可以用于所有分类问题和所有分类模型。像选择预测模型一样，需要仔细的实验来发现什么最适合你的项目。

在本教程中，您将发现一套数据采样技术，可用于平衡不平衡的类别数据集。

完成本教程后，您将知道:

*   不平衡类别数据集下机器学习的挑战。
*   使用数据采样技术平衡偏斜的类分布。
*   过采样、欠采样和方法组合的数据采样方法。

**用我的新书[Python 不平衡分类](https://machinelearningmastery.com/imbalanced-classification-with-python/)启动你的项目**，包括*分步教程*和所有示例的 *Python 源代码*文件。

我们开始吧。

![Tour of Data Resampling Methods for Imbalanced Classification](img/409d40bc6bef67e3795ec7c685a3a2ee.png)

不平衡分类的数据重采样方法之旅。新西兰，保留部分权利。

## 教程概述

本教程分为三个部分；它们是:

1.  一个不平衡的类分布问题
2.  用数据采样平衡类分布
3.  流行数据采样方法巡礼
    1.  过采样技术
    2.  欠采样技术
    3.  技术的结合

## 一个不平衡的类分布问题

不平衡分类涉及类别分布不相等的数据集。

这意味着训练数据集中属于每一类的例子的数量是不同的，通常很大。在类分布中有严重的偏差并不罕见，例如少数类中的例子与多数类中的例子之比为 1:10、1:1000 甚至 1:1000。

> ……我们将不平衡学习定义为具有严重数据分布偏差的数据表示和信息提取的学习过程，以开发有效的决策边界来支持决策过程。

—第 1 页，[不平衡学习:基础、算法和应用](https://amzn.to/32K9K6d)，2013。

虽然经常用两类分类问题来描述，但类不平衡也会影响那些有两个以上类的数据集，这些数据集可能有多个少数类或多个多数类。

不平衡类别数据集的一个主要问题是标准机器学习算法在这些数据集上表现不佳。许多机器学习算法依赖于训练数据集中的类分布来衡量当模型将被用于进行预测时观察每个类中的例子的可能性。

因此，许多机器学习算法，如决策树、k 近邻和神经网络，将因此了解到少数类不如多数类重要，并将更多注意力放在多数类上，并在多数类上表现更好。

> 不平衡数据集的问题在于，标准的分类学习算法通常偏向多数类(称为“负类”)，因此在少数类实例(称为“正”类)中有较高的错误分类率。

—第 79 页，[从不平衡数据集](https://amzn.to/307Xlva)中学习，2018。

这是一个问题，因为少数类正是不平衡分类问题中我们最关心的类。

这是因为多数类通常反映正常情况，而少数类代表诊断、错误、欺诈或其他类型异常情况的阳性情况。

## 用数据采样平衡类分布

不平衡分类问题最流行的解决方案是改变训练数据集的组成。

当我们对现有数据样本进行采样时，设计用于改变训练数据集中的类分布的技术通常被称为采样方法或重采样方法。

> 采样方法似乎是社区中占主导地位的方法，因为它们以直接的方式处理不平衡的学习。

—第 3 页，[不平衡学习:基础、算法和应用](https://amzn.to/32K9K6d)，2013。

采样方法如此常见的原因是因为它们易于理解和实现，并且因为一旦应用于转换训练数据集，就可以直接使用一套标准的机器学习算法。

这意味着，为平衡(或大部分平衡)分类而开发的数十或数百种机器学习算法中的任何一种都可以适合训练数据集，而无需对它们进行任何修改来适应观察中的不平衡。

> 基本上，我们可以尝试平衡班级频率，而不是让模型处理不平衡。采用这种方法消除了困扰模型训练的根本不平衡问题。

—第 427 页，[应用预测建模](https://amzn.to/2VRASxV)，2013 年。

像[朴素贝叶斯分类器](https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/)这样的机器学习算法从训练数据集中学习观察每个类的例子的可能性。通过将这些模型拟合到一个样本训练数据集中，使之具有一个人为的更均匀的类分布，它允许他们学习一个更少偏差的先验概率，而不是关注每个输入变量的细节(或证据)来区分类。

> 一些模型使用先验概率，例如朴素贝叶斯和判别分析分类器。除非手动指定，否则这些模型通常从训练数据中导出先验值。使用更平衡的先验或平衡的训练集可能有助于处理班级不平衡。

—第 426 页，[应用预测建模](https://amzn.to/2VRASxV)，2013 年。

采样仅在训练数据集上执行，该数据集由算法用来学习模型。它不会在保持测试或验证数据集上执行。原因是这样做的目的不是为了消除模型拟合中的类偏差，而是为了继续在真实的和代表目标问题领域的数据上评估结果模型。

因此，我们可以将数据采样方法视为解决训练数据集中相对类不平衡的问题，而忽略问题域中不平衡的根本原因。少数群体中所谓的相对罕见和绝对罕见之间的区别。

> 采样方法是处理不平衡数据的一种非常流行的方法。这些方法主要用于解决相对罕见的问题，但不能解决绝对罕见的问题。

—第 29 页，[不平衡学习:基础、算法和应用](https://amzn.to/32K9K6d)，2013。

在经过转换的数据集上评估模型，并删除或合成示例，可能会对表现提供一个误导性的、或许是乐观的估计。

训练数据集中使用的数据采样有两种主要类型:过采样和欠采样。在下一节中，我们将浏览每种类型的流行方法，以及结合多种方法的方法。

## 流行数据采样方法巡礼

有数十种(如果不是数百种)数据采样方法可供选择，以便调整训练数据集的类分布。

没有最好的数据采样方法，就像没有最好的机器学习算法一样。这些方法根据学习算法的选择以及训练数据集的密度和组成而有所不同。

> ……在许多情况下，采样可以减轻不平衡造成的问题，但在各种方法中没有明显的赢家。此外，许多建模技术对采样的反应不同，这进一步复杂化了使用哪个过程的简单指南的想法

—第 429 页，[应用预测建模](https://amzn.to/2VRASxV)，2013 年。

因此，仔细设计实验来测试和评估一套不同的方法和一些方法的不同配置是很重要的，以便发现什么最适合您的特定项目。

虽然有许多技术可供选择，但平均来说，可能有十几种更受欢迎，也可能更成功。在本节中，我们将对这些方法进行介绍，这些方法分为过采样、欠采样和组合方法的粗略分类。

> 该领域的代表性工作包括随机过采样、随机欠采样、带有数据生成的合成采样、基于聚类的采样方法以及采样和增强的集成。

—第 3 页，[不平衡学习:基础、算法和应用](https://amzn.to/32K9K6d)，2013。

以下部分回顾了一些更流行的方法，在二进制(两类)分类问题的上下文中描述，这是一种常见的做法，尽管大多数可以直接使用或适用于两类以上的不平衡分类。

这里的列表主要基于 Sklearn 友好库中可用的方法，称为[不平衡学习](https://github.com/Sklearn-contrib/imbalanced-learn)。有关数据采样方法的详细列表，请参见 2018 年出版的《从不平衡数据集中学习[一书中的第 5 章数据级预处理方法》](https://amzn.to/307Xlva)

**你最喜欢的数据采样技术是什么？**
**我是不是错过了好方法？**
在下面的评论里告诉我。

### 过采样技术

过采样方法复制少数类的例子，或者从少数类的例子中合成新的例子。

一些更广泛使用和实现的过采样方法包括:

*   随机过采样
*   合成少数过采样技术
*   边界线-SMOTE
*   SVM 边界过采样
*   自适应合成采样

让我们仔细看看这些方法。

最简单的过采样方法包括从训练数据集中的少数类中随机复制例子，称为**随机过采样**。

最流行也可能是最成功的过采样方法是**SMOTE**；这是合成少数过采样技术的缩写。

SMOTE 的工作方式是选择特征空间中靠近的示例，在特征空间中的示例之间绘制一条线，并沿着该线绘制一个新样本作为点。

SMOTE 方法有许多扩展，旨在对合成的多数类中的示例类型更具选择性。

**边界线-SMOTE** 包括选择那些被错误分类的少数民族类的实例，例如使用[k-最近邻分类模型](https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/)，并且仅生成难以分类的合成样本*。*

 ***边界过采样**是 SMOTE 的扩展，它将 SVM 拟合到数据集，并使用由支持向量定义的决策边界作为生成合成示例的基础，同样基于决策边界是需要更多少数示例的区域的思想。

**自适应合成采样** (ADASYN)是 SMOTE 的另一个扩展，它生成的合成样本与少数类中示例的密度成反比。它被设计成在特征空间中少数示例密度低的区域中创建合成示例，而在密度高的区域中创建较少或没有合成示例。

### 欠采样技术

欠采样方法从多数类中删除或选择示例的子集。

一些更广泛使用和实现的欠采样方法包括:

*   随机欠采样
*   压缩最近邻规则
*   差点采样不足
*   Tomek 链接欠采样
*   编辑最近邻居规则(ENN)
*   单边选择
*   邻里清洁规则(NCR)

让我们仔细看看这些方法。

最简单的欠采样方法包括从训练数据集中的多数类中随机删除示例，称为随机欠采样。

一组技术包括在多数类中选择一个健壮且有代表性的例子子集。

**压缩最近邻**规则，简称 CNN，是为了减少 k 最近邻算法所需的内存而设计的。它的工作原理是枚举数据集中的示例，并且仅当无法通过存储的当前内容对示例进行正确分类时，才将其添加到存储中，并且在少数类中的所有示例都添加到存储后，可以应用它来减少多数类中的示例数量。

**未遂事件**指的是使用 KNN 从多数类中选择例子的一系列方法。NearMiss-1 从多数类中选择与少数类中最接近的三个示例具有最小平均距离的示例。NearMiss-2 从多数类中选择与少数类最远的三个示例之间平均距离最小的示例。NearMiss-3 包括为少数类中最接近的每个示例选择给定数量的多数类示例。

另一组技术包括从多数类中选择要删除的示例。这些方法通常涉及识别那些难以分类的例子，因此增加了决策边界的模糊性。

也许最广为人知的删除欠采样方法被称为**Tomek link**，最初是作为压缩最近邻规则扩展的一部分开发的。Tomek Link 指的是训练数据集中的一对示例，这两个示例都是最近的邻居(在特征空间中具有最小距离)，并且属于不同的类。Tomek Links 通常是沿着类边界发现的错误分类的示例，大多数类中的示例被删除。

**编辑最近邻**规则，简称 ENN，是另一种选择删除示例的方法。该规则包括使用 k=3 个最近邻来定位数据集中那些分类错误的示例，并将其删除。

ENN 过程可以在同一数据集上重复多次，从而更好地优化多数类中的示例选择。这种扩展最初被称为“无限制编辑”，尽管它通常被称为“重复编辑最近邻”。

停留在“*选择保留*”vs“*选择删除*”系列欠采样方法，也有结合这两种方法的欠采样方法。

**单侧选择**，简称 OSS，是一种结合了 Tomek Links 和压缩最近邻(CNN)规则的欠采样技术。Tomek Links 方法用于移除类边界上有噪声的示例，而 CNN 用于移除多数类密度内部的冗余示例。

**邻域清理规则**，简称 NCR，是另一种组合欠采样技术，它结合了压缩最近邻(CNN)规则来移除冗余示例，以及编辑最近邻(ENN)规则来移除有噪声或不明确的示例。

### 技术的结合

尽管在训练数据集上单独使用过采样或欠采样方法可能是有效的，但是实验表明，将这两种类型的技术一起应用通常可以在所得的变换数据集上获得模型拟合的更好的整体表现。

一些更广泛使用和实现的数据采样方法组合包括:

*   SMOTE 和随机欠采样
*   SMOTE 和 Tomek 链接
*   移动和编辑最近邻规则

让我们仔细看看这些方法。

SMOTE 可能是最流行和最广泛使用的过采样技术。因此，它通常与一系列不同的欠采样方法配对。

最简单的配对包括将 SMOTE 与随机欠采样相结合，在提出该方法的论文中，该方法的表现优于单独使用 SMOTE。

通常将 SMOTE 与从数据集中选择要删除的示例的欠采样方法配对，该过程在 SMOTE 之后应用于数据集，从而允许编辑步骤同时应用于少数和多数类。其目的是从两个类中去除沿着类边界的噪声点，这似乎具有更好的分类器表现适合变换数据集的效果。

两个流行的例子包括使用 SMOTE 后删除 Tomek 链接，以及 SMOTE 后删除那些通过 KNN 模型错误分类的例子，即所谓的编辑最近邻规则。

## 进一步阅读

如果您想更深入地了解这个主题，本节将提供更多资源。

### 报纸

*   [SMOTE:合成少数过采样技术](https://arxiv.org/abs/1106.1813)，2011。
*   [平衡机器学习训练数据的几种方法的行为研究](https://dl.acm.org/citation.cfm?id=1007735)，2004。

### 书

*   [应用预测建模](https://amzn.to/2VRASxV)，2013。
*   [从不平衡数据集中学习](https://amzn.to/307Xlva)，2018。
*   [不平衡学习:基础、算法和应用](https://amzn.to/32K9K6d)，2013。

### 文章

*   [数据分析中的过采样和欠采样，维基百科](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis)。

## 摘要

在本教程中，您发现了一套数据采样技术，可用于平衡不平衡的类别数据集。

具体来说，您了解到:

*   不平衡类别数据集下机器学习的挑战。
*   使用数据采样技术平衡偏斜的类分布。
*   过采样、欠采样和多种方法组合的流行数据采样方法。

你有什么问题吗？
在下面的评论中提问，我会尽力回答。*