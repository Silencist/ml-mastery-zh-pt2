# 如何配置神经网络的层数和节点数

> 原文：<https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/>

最后更新于 2019 年 8 月 6 日

人工神经网络有两个控制网络架构或拓扑的主要超参数:层数和每个隐藏层中的节点数。

配置网络时，必须指定这些参数的值。

为您的特定预测建模问题配置这些超参数的最可靠方法是通过使用强大的测试工具进行系统实验。

对于机器学习领域的初学者来说，这可能是一颗难以吞下的药丸，他们正在寻找一种计算最佳层数和节点数的分析方法，或者简单的经验法则。

在这篇文章中，你将发现层和节点的作用，以及如何为你的预测建模问题接近多层感知器神经网络的配置。

看完这篇文章，你会知道:

*   单层和多层感知器网络的区别。
*   网络中有一个和多个隐藏层的价值。
*   配置网络层数和节点数的五种方法。

**用我的新书[更好的深度学习](https://machinelearningmastery.com/better-deep-learning/)启动你的项目**，包括*分步教程*和所有示例的 *Python 源代码*文件。

我们开始吧。

![How to Configure the Number of Layers and Nodes in a Neural Network](img/d8b64d656d79fbd7f5b956fa07d9280c.png)

如何配置神经网络中的层数和节点数
图片由[瑞安](https://www.flickr.com/photos/scorsese/7272760288/)提供，版权所有。

## 概观

该员额分为四个科；它们是:

1.  多层感知器
2.  如何计算层数？
3.  为什么有多层？
4.  要使用多少层和节点？

## 多层感知器

节点，也称为神经元或感知器，是一个具有一个或多个加权输入连接、以某种方式组合输入的传递函数和输出连接的计算单元。

节点随后被组织成层以构成网络。

单层人工神经网络，也叫单层，顾名思义，就是有单层的节点。单层中的每个节点都直接连接到一个输入变量，并贡献给一个输出变量。

> 单层网络只有一层活动单元。输入通过单层权重直接连接到输出。输出不相互作用，因此具有 N 个输出的网络可以被视为 N 个独立的单输出网络。

—第 15 页，[神经锻造:前馈人工神经网络中的监督学习](https://amzn.to/2vhyW8j)，1999。

单层网络可以扩展到多层网络，称为多层感知器。多层感知器，简称 MLP，是一种具有多个单层的人工神经网络。

它有一个连接到输入变量的输入层，一个或多个隐藏层，以及一个产生输出变量的输出层。

> 标准多层感知器(MLP)是单层感知器的级联。有一层输入节点、一层输出节点和一个或多个中间层。内部层有时被称为“隐藏层”，因为它们不能从系统的输入和输出直接观察到。

—第 31 页，[神经锻造:前馈人工神经网络中的监督学习](https://amzn.to/2vhyW8j)，1999。

我们可以将 MLP 的层类型总结如下:

*   **输入层**:输入变量，有时称为可见层。
*   **隐藏层**:输入和输出层之间的节点层。这些层可能有一层或多层。
*   **输出层**:产生输出变量的节点层。

最后，有一些术语用来描述神经网络的形状和能力；例如:

*   **大小**:模型中的节点数。
*   **宽度**:特定层中的节点数。
*   **深度**:神经网络中的层数。
*   **容量**:网络配置可以学习的功能类型或结构。有时被称为“*代表能力*”。
*   **架构**:网络中各层和节点的具体安排。

## 如何计算层数？

传统上，对于如何计算层数有一些分歧。

分歧集中在输入层是否被计算。有一种观点认为，它不应该被计算在内，因为输入不活跃；它们只是输入变量。我们将使用这个惯例；这也是《神经锻造*》一书中推荐的惯例。*

 *因此，具有一个输入层、一个隐藏层和一个输出层的 MLP 是一个 2 层 MLP。

MLP 的结构可以用一个简单的符号来概括。

这种方便的表示法总结了层数和每层中的节点数。每层中的节点数被指定为一个整数，从输入层到输出层依次排列，每层的大小由正斜杠字符(“/”)分隔。

例如，输入层有两个变量，一个隐藏层有八个节点，一个输出层有一个节点的网络将使用符号 2/8/1 来描述。

我建议在描述多层感知器神经网络的层及其大小时使用这种符号。

## 为什么有多层？

在我们考虑要指定多少层之前，重要的是要考虑为什么我们要有多个层。

单层神经网络只能用于表示线性可分函数。这意味着非常简单的问题，比如，分类问题中的两个类可以用一条线整齐地分开。如果你的问题相对简单，也许单层网络就足够了。

我们感兴趣解决的大多数问题都不是线性可分的。

多层感知器可用于表示凸区域。这意味着，实际上，他们可以学习在一些高维空间中围绕例子绘制形状，这些形状可以对它们进行分离和分类，从而克服线性可分性的限制。

事实上，李普曼在 1987 年的论文《神经网络计算导论》中有一个理论发现，表明具有两个隐藏层的 MLP 足以创建任何期望形状的分类区域。这是有指导意义的，尽管应该注意的是，没有给出在每个层中使用多少节点或者如何学习权重的指示。

进一步的理论发现和证明表明，MLPs 是[通用逼近器](https://en.wikipedia.org/wiki/Universal_approximation_theorem)。有了一个隐藏层，MLP 可以逼近我们需要的任何函数。

> 具体而言，通用近似定理指出，具有线性输出层和至少一个具有任何“挤压”激活函数(例如逻辑 sigmoid 激活函数)的隐藏层的前馈网络可以以任何期望的非零误差量近似从一个有限维空间到另一个有限维空间的任何 Borel 可测函数，只要网络被给予足够的隐藏单元。

—第 198 页，[深度学习](https://amzn.to/2IXzUIY)，2016。

这是一个经常被引用的理论发现，并且有大量关于它的文献。在实践中，我们同样不知道对于给定的问题，在单个隐藏层中使用多少节点，也不知道如何有效地学习或设置它们的权重。此外，已经提出了许多反例，说明不能通过单个一隐层 MLP 直接学习的函数，或者需要无穷多个节点的函数。

即使对于那些可以通过足够大的一个隐藏层 MLP 来学习的函数，使用两个(或更多)隐藏层来学习也会更有效。

> 既然一个足够大的隐藏层足以逼近大多数函数，为什么会有人使用更多呢？一个原因在于“足够大”这几个字。虽然单个隐藏层对于某些功能来说是最佳的，但是对于其他功能，单个隐藏层解决方案与具有更多层的解决方案相比效率非常低。

—第 38 页，[神经锻造:前馈人工神经网络中的监督学习](https://amzn.to/2vhyW8j)，1999。

## 要使用多少层和节点？

随着 MLPs 序言的结束，让我们进入你真正的问题。

您应该在多层感知器中使用多少层，每层有多少节点？

在这一节中，我们将列举解决这个问题的五种方法。

### 1)实验

一般来说，当我被问及 MLP 要使用多少层和节点时，我通常会回答:

> 我不知道。使用系统实验来发现什么最适合您的特定数据集。

我还是袖手旁观这个答案。

一般来说，您无法通过分析计算人工神经网络中的层数或每层使用的节点数来解决特定的现实预测建模问题。

层数和每层中的节点数是您必须指定的模型超参数。

你可能是第一个试图用神经网络解决你的特定问题的人。在你之前没人解决过。因此，没有人能告诉你如何配置网络的答案。

您必须使用强大的测试工具和受控实验来发现答案。例如，查看帖子:

*   [如何评估深度学习模型的技能](https://machinelearningmastery.com/evaluate-skill-deep-learning-models/)

不管你可能会遇到什么样的试探法，所有的答案都会回到仔细实验的需要，看看什么最适合你的特定数据集。

### 2)直觉

网络可以通过直觉进行配置。

例如，您可能有一种直觉，即需要深度网络来解决特定的预测建模问题。

深度模型提供了一个层次结构，从输入变量到输出变量，这些层次结构建立了越来越多的抽象层次。

给定对问题域的理解，我们可能认为需要深度层次模型来充分解决预测问题。在这种情况下，我们可以选择具有多层深度的网络配置。

> 选择深度模型编码了一个非常普遍的信念，即我们想要学习的函数应该包含几个更简单的函数的组合。这可以从表征学习的角度解释为，我们认为学习问题包括发现一组潜在的变异因素，这些因素又可以用其他更简单的潜在变异因素来描述。

—第 201 页，[深度学习](https://amzn.to/2IXzUIY)，2016。

这种直觉可以来自对领域的经验，对神经网络建模问题的经验，或者两者的某种混合。

以我的经验来看，直觉往往会因为实验而失效。

### 3)追求深度

古德费勒、本吉奥和库维尔在他们关于深度学习的重要教科书中强调，根据经验，在感兴趣的问题上，深度神经网络似乎表现得更好。

具体来说，他们陈述了在深度可能对直觉有益的情况下，使用深度神经网络作为统计参数的选择。

> 从经验来看，更大的深度似乎确实会导致更好地概括各种各样的任务。[……]这表明使用深度架构确实表达了模型所学习的功能空间的有用先验。

—第 201 页，[深度学习](https://amzn.to/2IXzUIY)，2016。

我们可以用这个论点来建议，使用深层网络，即具有许多层的网络，可能是一种启发式的方法来配置网络，以应对具有挑战性的预测建模问题。

这类似于从表格数据预测建模问题的[随机森林](https://machinelearningmastery.com/use-random-forest-testing-179-classifiers-121-datasets/)和[随机梯度提升](https://machinelearningmastery.com/start-with-gradient-boosting/)开始的建议，以在测试其他方法之前快速获得模型技能的上限。

### 4)借用想法

一个简单但可能耗时的方法是利用文献中报道的发现。

找一些研究论文，描述 MLPs 在预测问题上的应用，这些问题在某些方面与你的问题相似。记下这些论文中使用的网络配置，并将其作为测试问题配置的起点。

模型超参数的可转移性导致熟练的模型从一个问题到另一个问题是一个具有挑战性的开放问题，也是为什么模型超参数配置更像艺术而不是科学的原因。

然而，用于相关问题的网络层和节点数量是测试想法的良好起点。

### 5)搜索

设计自动搜索来测试不同的网络配置。

你可以从文学和直觉中寻找灵感。

一些流行的搜索策略包括:

*   **随机**:尝试层和每层节点的随机配置。
*   **网格**:尝试跨层数和每层节点数进行系统搜索。
*   **启发式**:尝试跨配置的定向搜索，如遗传算法或贝叶斯优化。
*   **穷举**:尝试所有的层组合和节点数；这对于小型网络和数据集可能是可行的。

对于大型模型、大型数据集以及两者的组合，这可能是一个挑战。减少或管理计算负担的一些想法包括:

*   在训练数据集的较小子集上拟合模型，以加快搜索速度。
*   积极地限制搜索空间的大小。
*   跨多个服务器实例并行化搜索(例如，使用[亚马逊 EC2 服务](https://machinelearningmastery.com/develop-evaluate-large-deep-learning-models-keras-amazon-web-services/))。

如果时间和资源允许，我建议系统化。

### 更大的

我见过无数的试探法，如何估计层数，或者神经元总数，或者每层神经元数。

我不想一一列举；我怀疑它们除了被证明的特殊情况之外，还能增加实际价值。

如果你对这个领域感兴趣，也许可以从“[神经锻造](https://amzn.to/2vhyW8j)一书中的“*第 4.4 节容量与尺寸*”开始。它总结了这方面的大量发现。这本书是从 1999 年开始的，所以如果你愿意的话，在这一领域还有将近 20 年的想法要走。

此外，参见*进一步阅读*部分(如下)中链接的一些讨论。

我错过了你最喜欢的配置神经网络的方法了吗？或者你知道一个关于这个话题的好的参考资料吗？
在下面的评论里告诉我。

## 进一步阅读

如果您想更深入地了解这个主题，本节将提供更多资源。

### 报纸

*   [神经网络计算导论](https://ieeexplore.ieee.org/abstract/document/1165576/)，1987。
*   [隐藏了多少层和节点？](https://www.tandfonline.com/doi/abs/10.1080/01431160802549278)，2009 年。

### 书

*   [神经锻造:前馈人工神经网络中的监督学习](https://amzn.to/2vhyW8j)，1999。
*   [深度学习](https://amzn.to/2IXzUIY)，2016 年。

### 文章

*   [维基百科上的人工神经网络](https://en.wikipedia.org/wiki/Artificial_neural_network)
*   [维基百科上的通用近似定理](https://en.wikipedia.org/wiki/Universal_approximation_theorem)
*   [我应该使用多少隐藏层？，comp . ai . neural-net 常见问题解答](http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-9.html)

### 讨论

*   [前馈神经网络中隐藏层和节点的个数如何选择？](https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw)
*   [神经网络隐藏层节点数](https://stats.stackexchange.com/questions/160887/number-of-nodes-in-hidden-layers-of-neural-network)
*   [多层感知器(MLP)架构:选择隐藏层数和隐藏层大小的标准？](https://stackoverflow.com/questions/10565868/multi-layer-perceptron-mlp-architecture-criteria-for-choosing-number-of-hidde)
*   [在深度学习中，如何选择最佳层数和神经元数？](https://www.quora.com/In-deep-learning-how-do-I-select-the-optimal-number-of-layers-and-neurons)

## 摘要

在这篇文章中，你发现了层和节点的作用，以及如何配置多层感知器神经网络。

具体来说，您了解到:

*   单层和多层感知器网络的区别。
*   网络中有一个和多个隐藏层的价值。
*   配置网络层数和节点数的五种方法。

你有什么问题吗？
在下面的评论中提问，我会尽力回答。*