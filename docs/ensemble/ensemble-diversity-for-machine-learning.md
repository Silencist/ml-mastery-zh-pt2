# 机器学习集成多样性的温和介绍

> 原文：<https://machinelearningmastery.com/ensemble-diversity-for-machine-learning/>

集成学习将来自机器学习模型的预测结合起来用于分类和回归。

我们追求使用集成方法来实现**改进的预测表现**，正是这种对任何贡献模型的改进定义了集成是否良好。

好的集合中存在的一个特性是贡献模型所做预测的多样性。多样性是一个模糊的概念，因为它没有被精确地定义；然而，它为设计好的集成模型提供了一个有用的实用启发。

在这篇文章中，你将在机器学习中发现**集成多样性**。

看完这篇文章，你会知道:

*   一个好的集成团比任何有贡献的模型都有更好的表现。
*   集合多样性是一个好的集合的属性，其中贡献模型对相同的输入产生不同的误差。
*   寻求独立的模型和不相关的预测为思考和将多样性引入集合模型提供了指导。

**用我的新书[Python 集成学习算法](https://machinelearningmastery.com/ensemble-learning-algorithms-with-python/)启动你的项目**，包括*分步教程*和所有示例的 *Python 源代码*文件。

我们开始吧。

![A Gentle Introduction to Ensemble Diversity for Machine Learning](img/c36e97cdafbb2cddcc0673cbd9108d5b.png)

机器学习集成多样性简介
图片由[贝恩德·泰勒](https://www.flickr.com/photos/bernd_thaller/45006958281/)提供，版权所有。

## 教程概述

本教程分为三个部分；它们是:

1.  什么是好的集成
2.  什么是群体多样性
3.  增加多样性的方法

## 什么是好的集成

集成是一种机器学习模型，它结合了来自多个其他模型的预测。

这往往具有减少预测误差和提高模型泛化能力的效果。但情况并非总是如此。

有时候，这个集成团的表现并不比这个集成团中一个表现出色的成员好。更糟糕的是，有时候一个集成团的表现会比任何一个参与的成员都差。

这就提出了一个问题，什么是好的集成。

好的集成团是比任何贡献成员表现更好的集成团。也就是说，它是对于回归具有较低预测误差或者对于分类具有较高准确率的模型。

*   **好的集合**:比任何单一贡献模型表现更好的模型。

这可以使用训练和测试集或重采样技术(如 k 倍交叉验证)根据经验进行评估。可以类似地为每个有贡献的模型估计结果，并将结果直接进行比较，以查看是否满足“*好的集合*的定义。

一个好的集成有哪些特性使其区别于其他集成，这些集成的表现与任何贡献成员一样好或更差？

这是一个被广泛研究的问题，有很多想法。一致性就是好的集成有**多样性**。

## 什么是群体多样性

集合多样性指的是由集合成员做出的决定或预测的差异。

> 集成多样性，即个体学习器之间的差异，是集成方法中的一个基本问题。

—第 99 页，[集合方法](https://amzn.to/2XZzrjG)，2012。

做出相同预测的两个集成成员被认为是不多样的。

在所有情况下做出完全不同预测的集合是最大程度多样化的，尽管这是最不可能的。

> 在任何给定的样本上产生不同的误差在基于集合的系统中是至关重要的。毕竟，如果所有的集成成员都提供相同的输出，那么他们的组合就不会有什么收获。

—第 5 页，[集成机器学习](https://amzn.to/2C7syo5)，2012。

因此，为了构建一个好的集合，在预测中需要或者甚至需要某种程度的多样性。在讨论中，这通常被简化为对不同集合成员的期望，例如模型本身，这反过来将产生不同的预测，尽管预测的多样性确实是我们所寻求的。

理想情况下，多样性意味着每个集成成员做出的预测是独立且不相关的。

> …分类器输出应该是独立的，或者最好是负相关的。

—第 5 页，[集成机器学习](https://amzn.to/2C7syo5)，2012。

独立性是概率论中的一个术语，指的是一个事件不影响另一个事件发生的概率的情况。事件可以以许多不同的方式相互影响。如果一个集成试图修正它所做的预测，它可能会影响另一个集成。

因此，根据集合类型，模型可以是自然相关的或独立的。

*   **独立性**:一个事件的发生是否影响后续事件发生的概率。

相关性是统计学中的一个术语，指的是两个一起变化的变量。通常计算-1.0 和 1.0 之间的归一化相关分数，其中分数 0.0 表示不相关，例如不相关。得分为 1.0 或-1.0 一分别表示完全正相关和负相关，并表示两个模型总是预测相同(或相反)的结果。

> ……如果学习器是独立的，即[相关性] = 0，则集成将获得比单个学习器更小的误差因子 T；如果学习器完全相关，即[相关性] = 1，则不能从组合中获得任何收益。

—第 99 页，[集合方法](https://amzn.to/2XZzrjG)，2012。

在实践中，集成在它们的预测中经常表现出弱的或适度的正相关。

*   **相关性**:变量一起变化的程度。

因此，集合模型是从组成模型构建的，这些组成模型在所做的决策或预测之间可能具有或不具有某种依赖性和某种相关性。构建良好的集成是一项具有挑战性的任务。

例如，组合一堆表现最好的模型可能会导致整体效果不佳，因为模型做出的预测高度相关。非直觉地，你最好将一些表现最好的单个模型的预测与一些较弱模型的预测结合起来。

> 因此，希望学习器个体准确、多样。只结合准确的学习器往往比结合一些准确的学习器和一些相对较弱的学习器更糟糕，因为互补性比纯粹的准确性更重要。

—第 100 页，[集合方法](https://amzn.to/2XZzrjG)，2012 年。

可悲的是，没有一个普遍认同的集合多样性的衡量标准，独立性和相关性的想法只是思考好的集合的属性的指南或代理。

> 不幸的是，尽管多样性至关重要，但我们仍然没有对多样性有一个清晰的认识；例如，目前还没有公认的多样性的正式定义。

—第 100 页，[集合方法](https://amzn.to/2XZzrjG)，2012 年。

然而，作为指导，它们是有用的，因为我们可以设计出试图减少模型之间相关性的技术。

## 增加多样性的方法

发展良好集成的目标是通过增加集成成员的多样性来考虑的。

如果集合中的模型共享用于训练模型的相同算法和/或用于训练模型的相同数据集，则它们可能更加依赖。出于同样的一般原因，集合中的模型在它们的预测之间可能具有更高的相关性。

因此，使模型和/或训练数据更加不同的方法是期望的。

> 多样性可以通过输入数据的不同呈现来获得，如装袋、学习器设计的变化，或者通过在输出中添加惩罚来鼓励多样性。

—第 93 页，[使用集成方法的模式分类](https://amzn.to/2zxc0F7)，2010。

有一个框架来思考管理集成多样性的技术可能会有所帮助，而且有很多可以选择。

例如，周志华在他 2012 年出版的《集成方法:基础和算法》一书的第 5 章中提出了一个由四种方法组成的框架来产生多样性。概括来说，它们是:

*   **数据采样操作**:例如，针对每个模型对训练数据集进行不同的采样。
*   **输入特征操作**:例如，在不同组的输入特征上训练每个模型。
*   **学习参数操作**:比如训练不同超参数值的模型。
*   **输出表示操纵**:例如，训练具有不同修改目标值的模型。

也许最常见的方法是改变训练数据，即数据样本和输入特征，通常组合在一个方法中。

对于另一个用于生成多样集成的分类法的例子，在他 2010 年出版的名为《[使用集成方法的模式分类》](https://amzn.to/2zxc0F7)的书的第 4 章中，Lior Rokach 提出了一个类似的分类法，总结如下:

*   **操纵诱导物**，例如操纵模型的训练方式。
    *   改变超参数。
    *   起点不同。
    *   改变优化算法。
*   **操纵训练样本**，例如操纵用于训练的数据。
    *   重采样。
*   **改变目标属性表示**，例如操纵目标变量。
    *   改变编码。
    *   纠错码。
    *   标签交换。
*   **划分搜索空间**，例如操纵输入特征的数量。
    *   随机子空间。
    *   特征选择。
*   **杂交**，例如改变模型类型或上述方法的混合。

混合方法在流行的集成方法中是常见的，该集成方法在单个算法中组合多种方法来产生多样性，以及简单地改变组成集成的算法(模型类型)。

> 将竞争模型捆绑到集成中几乎总能提高泛化能力，而使用不同的算法作为扰动算子是获得必要的组件多样性的有效方法。

—第 89 页，[数据挖掘中的集成方法](https://amzn.to/3frGM1A)，2010。

这突出表明，尽管我们可以研究量化一个集合的多样性，但相反，大部分努力是在开发产生多样性的技术上。

我们可以利用这些知识来开发我们自己的集成方法，首先尝试标准且易于理解的集成学习方法，然后根据我们特定的数据集对它们进行定制，同时考虑模型独立性和预测相关性，以最大限度地利用它们。

## 进一步阅读

如果您想更深入地了解这个主题，本节将提供更多资源。

### 书

*   [使用集成方法的模式分类](https://amzn.to/2zxc0F7)，2010。
*   [集成方法](https://amzn.to/2XZzrjG)，2012。
*   [集成机器学习](https://amzn.to/2C7syo5)，2012。
*   [数据挖掘中的集成方法](https://amzn.to/3frGM1A)，2010。

### 文章

*   一起学习，维基百科。
*   [一起学习，学院派](http://www.scholarpedia.org/article/Ensemble_learning)。

## 摘要

在这篇文章中，你发现了机器学习中的集成多样性。

具体来说，您了解到:

*   一个好的集成团比任何有贡献的模型都有更好的表现。
*   集合多样性是一个好的集合的属性，其中贡献模型对相同的输入产生不同的误差。
*   寻求独立的模型和不相关的预测为思考和将多样性引入集合模型提供了指导。

**你有什么问题吗？**
在下面的评论中提问，我会尽力回答。