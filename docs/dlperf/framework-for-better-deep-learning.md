# 更好的深度学习框架

> 原文：<https://machinelearningmastery.com/framework-for-better-deep-learning/>

最后更新于 2019 年 8 月 6 日

现代深度学习库(如 Keras)允许您在几分钟内用几行代码定义并开始拟合各种神经网络模型。

然而，配置神经网络以在新的预测建模问题上获得良好的表现仍然是一个挑战。

取得好表现的挑战可以分为三个主要方面:学习问题、概括问题和预测问题。

一旦您诊断出网络中存在的特定类型的问题，就可以选择一套经典和现代技术来解决问题并提高表现。

在这篇文章中，您将发现一个框架，用于使用深度学习模型和技术来诊断表现问题，您可以使用这些模型和技术来定位和改进每个特定的表现问题。

看完这篇文章，你会知道:

*   定义和拟合神经网络从未如此简单，尽管在新问题上获得良好的表现仍然具有挑战性。
*   神经网络建模表现问题可以分解为学习型、泛化型和预测型问题。
*   有几十年的技术以及现代方法可以用来针对每种类型的模型表现问题。

**用我的新书[更好的深度学习](https://machinelearningmastery.com/better-deep-learning/)启动你的项目**，包括*分步教程*和所有示例的 *Python 源代码*文件。

我们开始吧。

![Framework for Better Deep Learning](img/62976673f9a5a9f98107163198ef4c57.png)

更好的深度学习框架
图片由 [Anupam_ts](https://www.flickr.com/photos/anupamsrivastava/9137169363/) 提供，保留部分权利。

## 概观

本教程分为七个部分；它们是:

1.  神经网络复兴
2.  配置神经网络的挑战
3.  系统更好的深度学习框架
4.  更好的学习技巧
5.  更好的概括技巧
6.  更好的预测技术
7.  如何使用框架

## 神经网络复兴

历史上，神经网络模型必须从零开始编码。

你可能会花上几天或几周的时间将描述不佳的数学翻译成代码，花上几天或几周的时间调试你的代码，只是为了运行一个简单的神经网络模型。

那些日子已经过去了。

如今，您只需几行代码就可以在几分钟内定义并开始拟合大多数类型的神经网络，这要归功于像 Keras 这样的开源库，它建立在像 TensorFlow 这样复杂的数学库之上。

这意味着可以快速开发和评估标准模型(如多层感知器)以及更复杂的模型(如卷积神经网络和递归神经网络，如长短期记忆网络)，这些模型以前可能超出了大多数从业者的实现能力。

作为深度学习的实践者，我们生活在一个令人惊叹和富有成效的时代。

然而，即使可以快速定义和评估新的神经网络模型，也很少有人指导如何实际配置神经网络模型以充分利用它们。

## 配置神经网络的挑战

配置神经网络模型通常被称为“黑暗艺术”

这是因为没有针对给定问题配置网络的硬性规则。我们无法分析计算给定数据集的最佳模型类型或模型配置。

相反，有几十年的技术、启发、技巧、诀窍和其他隐性知识在代码、论文、博客文章和人们的头脑中传播。

在一个问题上配置神经网络的捷径是复制另一个类似问题的网络配置。但是这种策略很少导致好的结果，因为模型配置不能跨问题转移。也有可能你处理的是预测建模问题，这些问题与文献中描述的其他问题非常不同。

幸运的是，在配置和训练神经网络时，有一些已知的技术可以解决特定的问题，这些技术可以在像 Keras 这样的现代深度学习库中获得。

此外，在过去的 5 到 10 年中，在诸如激活函数、自适应学习率、正则化方法和[集成技术](https://machinelearningmastery.com/ensemble-methods-for-deep-learning-neural-networks/)等领域已经有了发现，这些发现已经被证明可以显著提高神经网络模型的表现，而不管它们的具体类型如何。

技术是可用的；你只需要知道它们是什么以及何时使用它们。

## 系统更好的深度学习框架

不幸的是，您不能简单地对用于提高深度学习表现的技术进行网格搜索。

几乎普遍的是，它们独特地改变了训练数据、学习过程、模型架构等方面。相反，您必须诊断您的模型存在的表现问题的类型，然后仔细选择和评估针对该诊断问题定制的给定干预。

就深度学习神经网络模型的不良表现而言，有三种类型的问题很容易诊断；它们是:

*   **学习上的问题**。学习中的问题表现在模型不能有效地学习训练数据集，或者在学习训练数据集时表现出缓慢的进度或糟糕的表现。
*   **泛化的问题**。泛化的问题表现在一个模型中，该模型过度扩展了训练数据集，并且在保持数据集上表现不佳。
*   **预测问题**。预测的问题表现在随机训练算法中，对最终模型有很大影响，导致行为和表现的高度变化。

这种细分为思考深度学习模型的表现提供了一种系统的方法。

这些关注领域之间有一些自然的重叠和互动。例如，学习方面的问题会影响模型的泛化能力以及最终模型预测的差异。

提议的细分中三个领域之间的顺序关系允许深度学习模型表现的问题首先被隔离，然后用特定的技术或方法作为目标。

我们可以将有助于解决这些问题的技术总结如下:

*   **更好的学习**。响应于训练数据集改进或加速神经网络模型权重自适应的技术。
*   **更好的概括**。提高神经网络模型在保持数据集上的表现的技术。
*   **更好的预测**。降低最终模型表现差异的技术。

现在，我们已经有了一个使用深度学习神经网络系统诊断表现问题的框架，让我们来看一些可能用于这三个关注领域的技术示例。

## 更好的学习技巧

更好的学习技术是对神经网络模型或学习算法的那些改变，这些改变响应于训练数据集来改善或加速模型权重的自适应。

在本节中，我们将回顾用于改进模型权重自适应的技术。

这从仔细配置与使用随机梯度下降算法优化神经网络模型和使用误差反向传播算法更新权重相关的超参数开始；例如:

*   **配置批量**。包括探索批量、随机(在线)或[小批量梯度下降](https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/)等变量是否更合适。
*   **配置学习率**。包括了解不同学习率对你的问题的影响，以及像亚当这样的现代适应性学习率方法是否合适。
*   **配置损耗功能**。包括理解不同损失函数的解释方式，以及替代损失函数是否适合您的问题。

这还包括简单的数据准备和更深层输入的自动重新缩放。

*   **数据缩放技术**。包括小网络权重对输入变量规模的敏感性以及目标变量中的大误差对权重更新的影响。
*   **批量归一化**。包括对网络模型深层层输入分布变化的敏感性，以及标准化层输入以增加输入一致性和学习过程稳定性的好处。

随机梯度下降是一种通用的优化算法，可以应用于广泛的问题。然而，优化过程(或学习过程)可能变得不稳定，需要具体的干预措施；例如:

*   [**【梯度消失】**](https://machinelearningmastery.com/how-to-fix-vanishing-gradients-using-the-rectified-linear-activation-function/) 。防止深层多层网络的训练导致靠近输入层的层没有更新它们的权重；这可以使用现代激活函数来解决，例如整流线性激活函数。
*   **爆炸梯度**。大的权重更新导致数字上溢或下溢，使得网络权重采用 NaN 或 Inf 值；可以使用梯度缩放或梯度裁剪来解决。

某些预测建模问题的数据限制会妨碍有效的学习。可以使用专门的技术来启动优化过程，提供一组有用的初始权重，甚至可以用于特征提取的整个模型；例如:

*   [**【贪婪逐层预训练】**](https://machinelearningmastery.com/greedy-layer-wise-pretraining-tutorial/) 。在模型中一次添加一个层，学习解释先前层的输出，并允许开发更深层次的模型:深度学习领域的里程碑技术。
*   [**转学**](https://machinelearningmastery.com/transfer-learning-for-deep-learning/) 。其中模型是在不同的、但以某种方式相关的预测建模问题上训练的，然后用于播种权重或者作为特征提取模型被大量使用，以向在感兴趣的问题上训练的模型提供输入。

你有没有使用其他技术来提高学习？
在下面的评论里告诉我。

## 更好的概括技巧

更好的泛化技术是改变神经网络模型或学习算法，以减少模型过拟合训练数据集的影响，并提高模型在保持验证或测试数据集上的表现。

在本节中，我们将回顾在训练过程中减少模型泛化的技术。

旨在减少泛化误差的技术通常被称为正则化技术。几乎普遍而言，正则化是通过某种方式降低或限制模型复杂性来实现的。

也许最广为人知的模型复杂性度量是模型权重的大小。具有大权重的模型是一种迹象，表明它可能过度专用于训练数据中的输入，使得它在对新的未知数据进行预测时不稳定。通过权重正则化保持权重小是一种强大且广泛使用的技术。

*   **权重正则化**。对损失函数的改变，按照模型权重的标准(大小)来惩罚模型，鼓励更小的权重，从而降低模型的复杂性。

不是简单地通过更新的损失函数来鼓励权重保持较小，而是可以使用约束来强制权重较小。

*   **重量约束**。当权重的[向量范数](https://machinelearningmastery.com/vector-norms-machine-learning/)超过阈值时，更新模型以重新缩放权重。

神经网络层的输出，无论该层在层堆栈中的什么位置，都可以被认为是关于输入的内部表示或一组提取的特征。更简单的内部表示可以对模型产生正则化效果，并且可以通过鼓励稀疏性(零值)的约束来鼓励。

*   [**【活动正规化】**](https://machinelearningmastery.com/how-to-reduce-generalization-error-in-deep-neural-networks-with-activity-regularization-in-keras/) 。损失函数的一种变化，它按照层激活的范数(大小)比例惩罚模型，鼓励更小或更稀疏的内部表示。

噪声可以被添加到模型中，以鼓励在训练期间关于来自先前层的原始输入或输出的鲁棒性；例如:

*   **输入噪声**。在输入层或隐藏层之间添加统计变化或噪声，以减少模型对特定输入值的依赖。
*   **丢弃**。在训练网络以打破跨层节点之间的紧密耦合时，从概率上移除连接(权重)。

通常，过拟合可能仅仅是由于在训练数据集上训练模型的时间过长。一个简单的解决办法就是早点停止训练。

*   **提前停机**。在训练过程中监控等待验证数据集的模型表现，并在验证集的表现开始下降时停止训练过程。

您是否使用了其他技术来提高概括能力？
在下面的评论里告诉我。

## 更好的预测技术

更好的预测技术是补充模型训练过程的技术，以减少最终模型预期表现的差异。

在本节中，我们将回顾降低最终深度学习神经网络模型的预期方差的技术。

最终模型表现的差异可以通过增加偏差来减少。将偏差引入最终模型的最常见方式是将多个模型的预测结合起来。这被称为集成学习。

集成学习不仅可以减少最终模型的表现差异，还可以带来更好的预测表现。

有效的集成学习方法要求每个有贡献的模型都有技能，这意味着模型做出的预测比随机的更好，但是模型之间的预测误差具有低相关性。这意味着，文工团成员模特应该有技巧，但方式不同。

这可以通过改变整体的一个方面来实现；例如:

*   改变用于适应每个成员的培训数据。
*   改变对集合预测有贡献的成员。
*   改变集合成员的预测组合方式。

可以通过在数据集的不同子样本上拟合模型来改变训练数据。

这可能涉及在训练数据集的不同随机选择的子集上拟合和保留模型，在 k-fold 交叉验证中保留每个折叠的模型，或者使用 bootstrap 方法(例如 bootstrap 聚合)替换保留不同样本的模型。总的来说，我们可以把这些方法看作是重采样集合。

*   **重采样集合**。模型集合适合训练数据集的不同样本。

也许改变集合成员的最简单方法包括在训练数据集上从多次运行的学习算法中收集模型。随机学习算法将在每次运行中产生稍微不同的拟合，这又会产生稍微不同的拟合。在多次运行中平均模型将确保表现保持一致。

*   **模型平均集合**。在同一数据集上的同一学习算法的多次运行中重新训练模型。

这种方法的变化可能涉及具有不同超参数配置的训练模型。

训练多个最终深度学习模型可能会很昂贵，尤其是当一个模型可能需要几天或几周的时间来适应时。

另一种方法是收集模型，在一次训练中用作贡献的集成成员；例如:

*   **水平集成**。在一次训练结束时，集合成员从一个连续的训练时期块中收集。
*   **快照集成**。使用积极循环学习率的训练运行，其中在学习率的每个循环的低谷收集集成成员。

组合来自多个集合成员的预测的最简单方法是在回归的情况下计算预测的平均值，或者在分类的情况下计算统计模式或最频繁的预测。

或者，可以学习组合来自多个模型的预测的最佳方式；例如:

*   **加权平均集合(混合)**。使用指示每个模型中的信任度的学习系数来加权每个集成成员对集成预测的贡献。
*   **堆叠概括([堆叠](https://machinelearningmastery.com/stacking-ensemble-for-deep-learning-neural-networks/) )** 。一个新的模型被训练来学习如何最好地组合来自集合成员的预测。

作为组合来自集合成员的预测的替代方案，模型本身可以被组合；例如:

*   **平均模型权重集合**。来自多个神经网络模型的权重被平均成用于进行预测的单个模型。

您是否使用了其他技术来减少最终模型的差异？
在下面的评论里告诉我。

## 如何使用框架

我们可以将技术组织成更好的学习、泛化和预测三个领域，作为一个系统框架来提高你的神经网络模型的表现。

有太多的技术来合理地调查和评估你的项目中的每一个。

相反，你需要有条不紊，有针对性地使用技术来解决一个明确的问题。

### 步骤 1:诊断表现问题

使用这个框架的第一步是诊断模型的表现问题。

一个强大的诊断工具是在给定数量的训练时期内，在训练和验证数据集上计算损失的[学习曲线](https://machinelearningmastery.com/how-to-control-neural-network-model-capacity-with-nodes-and-layers/)和特定问题的度量(如回归的 RMSE 或分类的准确性)。

*   如果在训练数据集上的损失很差，停滞不前，或者没有改善，也许你有一个学习问题。
*   如果训练数据集中的损失或特定于问题的度量在验证数据集中持续改进并变得更糟，那么您可能会遇到泛化问题。
*   如果验证数据集中的损失或特定于问题的指标在接近运行结束时显示出较高的方差，则可能存在预测问题。

### 步骤 2:选择和评估一种技术

回顾旨在解决您的问题的技术。

选择一种看起来很适合您的模型和问题的技术。这可能需要一些先前的技术经验，对于初学者来说可能具有挑战性。

值得庆幸的是，有一些启发式和最佳实践可以很好地解决大多数问题。

例如:

*   **学习问题**:拨入学习算法的超参数；具体来说，学习率提供了最大的杠杆作用。
*   **泛化问题**:使用权重正则化和提前停止在大多数问题最多的模型上效果很好，或者尝试提前停止的脱落。
*   **预测问题**:对从多次运行或一次运行的多个时期收集的模型中的预测进行平均，以增加足够的偏差。

选择一个干预，然后读一点点，包括它是如何工作的，为什么它工作，重要的是，在你使用它之前，为从业者找到如何使用它来解决你的问题的例子。

### 步骤 3:转到步骤 1

一旦您确定了一个问题并通过干预解决了它，请重复该过程。

开发一个更好的模型是一个迭代的过程，可能需要在多个层次上的多种干预，这些干预是相辅相成的。

这是一个经验过程。这意味着您依赖于测试工具的健壮性来为您提供干预前后的可靠表现总结。花时间来确保您的测试工具是健壮的，保证训练、测试和验证数据集是干净的，并从您的问题域中提供适当的代表性观察样本。

## 进一步阅读

如果您想更深入地了解这个主题，本节将提供更多资源。

### 书

*   [深度学习](https://amzn.to/2NJW3gE)，2016 年。
*   [模式识别与机器学习](https://amzn.to/2Q2rEeP)，2006。
*   [神经锻造:前馈人工神经网络中的监督学习](https://amzn.to/2poqOxc)，1999。

### 报纸

*   [深度架构基于梯度的训练实用建议](https://arxiv.org/abs/1206.5533)，2012。

### 邮件

*   [机器学习表现提升小抄](https://machinelearningmastery.com/machine-learning-performance-improvement-cheat-sheet/)
*   [如何提高深度学习表现](https://machinelearningmastery.com/improve-deep-learning-performance/)

### 文章

*   [神经网络常见问题](ftp://ftp.sas.com/pub/neural/FAQ.html)
*   [必须知道深层神经网络的技巧/诀窍](http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html)

## 摘要

在这篇文章中，您发现了一个使用深度学习模型和技术诊断表现问题的框架，您可以使用该框架来定位和改进每个特定的表现问题。

具体来说，您了解到:

*   定义和拟合神经网络从未如此简单，尽管在新问题上获得良好的表现仍然具有挑战性。
*   神经网络建模表现问题可以分解为学习型、泛化型和预测型问题。
*   有几十年的技术以及现代方法可以用来针对每种类型的模型表现问题。

你有什么问题吗？
在下面的评论中提问，我会尽力回答。